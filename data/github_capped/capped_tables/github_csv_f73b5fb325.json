{
  "columns": [
    "Question",
    "A",
    "B",
    "C",
    "D"
  ],
  "data": [
    [
      "What is the key difference between Unigram tokenization and BPE when applied in text preprocessing?",
      "Unigram starts with a small vocabulary and adds tokens, while BPE removes tokens to optimize",
      "Unigram starts with a large vocabulary and removes tokens, while BPE merges tokens to optimize",
      "BPE uses frequency-based tokenization, while Unigram applies random selection",
      "Unigram focuses on character embeddings, while BPE uses word embeddings"
    ],
    [
      "How does Gradio's gallery component simplify displaying image datasets?",
      "By generating image embeddings for input and output",
      "By allowing batch upload with customizable columns and layout",
      "By integrating directly with Hugging Face datasets",
      "By automatically preprocessing images for display"
    ],
    [
      "What role does the Viterbi algorithm play in Unigram tokenization?",
      "It identifies the tokens with the lowest frequencies",
      "It computes the best segmentation of a word into tokens based on their probabilities",
      "It aligns tokens to embeddings in the pretraining phase",
      "It removes redundant tokens from the vocabulary"
    ],
    [
      "What makes the Kandinsky 2.2 training scripts unique for text-to-image models?",
      "Exclusive use of text embeddings without image processing",
      "Integration of CLIP-based image and text processors for embedding generation",
      "Dependence on GANs for image generation",
      "Avoidance of fine-tuning for domain-specific datasets"
    ],
    [
      "What preprocessing steps are essential for Proximal Policy Optimization (PPO) reinforcement learning?",
      "Data normalization and batch augmentation",
      "Environment setup with virtual display and action-space discretization",
      "Only using predefined reward functions",
      "Manual adjustment of agent hyperparameters"
    ],
    [
      "Why is `gradient_checkpointing` important in training Kandinsky 2.2?",
      "It improves model accuracy by skipping gradients during backpropagation",
      "It reduces memory usage, enabling larger models to fit on GPUs",
      "It eliminates the need for dataset augmentation",
      "It ensures compatibility with older PyTorch versions"
    ],
    [
      "What is a core advantage of Hugging Face's CleanRL PPO implementation for reinforcement learning?",
      "Simplifies reward computation by avoiding hyperparameter tuning",
      "Provides single-file, research-friendly implementations with evaluation support",
      "Removes the need for action-value functions in RL tasks",
      "Limits compatibility to Gym environments"
    ],
    [
      "How does the Unigram tokenization algorithm ensure efficient vocabulary pruning?",
      "By merging high-frequency substrings into tokens",
      "By computing token probabilities and removing those with minimal impact on loss",
      "By randomly selecting tokens to remove from the vocabulary",
      "By discarding base characters first to minimize token overlap"
    ],
    [
      "Why is the CLIP tokenizer critical in Kandinsky 2.2 training workflows?",
      "It generates embeddings used directly by the image generator",
      "It tokenizes only image-related data for the decoder",
      "It precomputes embedding gradients to optimize training speed",
      "It replaces text data preprocessing entirely"
    ],
    [
      "What is the purpose of the `Gallery` component in Gradio applications?",
      "To preprocess image data for training pipelines",
      "To create an interactive display for image datasets",
      "To generate augmented image versions for fine-tuning tasks",
      "To align image captions with text embeddings"
    ],
    [
      "What is the primary purpose of `gradient_checkpointing` in Kandinsky 2.2 training?",
      "To improve model accuracy through advanced gradient computation",
      "To reduce memory consumption during training",
      "To accelerate training by skipping gradients",
      "To ensure compatibility with GPU-less environments"
    ],
    [
      "What distinguishes the Viterbi algorithm in Unigram tokenization?",
      "It merges frequent substrings into tokens",
      "It computes the most probable segmentation of words into tokens",
      "It eliminates low-frequency tokens from the vocabulary",
      "It aligns embeddings with text representations"
    ],
    [
      "How does the CLIP tokenizer support text-to-image models like Kandinsky 2.2?",
      "By aligning text and image datasets for preprocessing",
      "By generating embeddings that connect textual prompts to visual outputs",
      "By creating captions for images in datasets",
      "By focusing on monolingual text preprocessing"
    ]
  ]
}