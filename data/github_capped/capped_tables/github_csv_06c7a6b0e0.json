{
  "columns": [
    "id",
    "title",
    "description",
    "project_name",
    "status_name",
    "priority_id",
    "type_id",
    "assignee_id",
    "labels"
  ],
  "data": [
    [
      13415814,
      "ResourceLimitCache leaks permits",
      "{{ResourceLimitCache}} limits its size by using a group of permits.  {{put}} requires free permit before it can add data.  However, {{removeIf}} does not release permits.",
      "HDDS",
      "Resolved",
      2,
      1,
      1699,
      "pull-request-available"
    ],
    [
      13543455,
      "Log more information about failed EC block allocation",
      "We should include more information in the log if EC block allocation is rejected due to too many open pipelines.  ALLOCATE_BLOCK request's ExcludeList is not included in SCM audit log (maybe due to potentially large size?).  However, this piece of information may be important to understand why block allocation fails.",
      "HDDS",
      "Resolved",
      3,
      4,
      1699,
      "pull-request-available"
    ],
    [
      13517234,
      "Simplify DatanodeDetails#toString to improve log messages",
      "{{DatanodeDetails#toString}} outputs too much detail for it to be usable in each and every log message related to datanodes.  Thus log statements currently have to build their own output (e.g. for list of hosts, etc.), leading to duplication.\n\nThe goal of this task is to replace {{toString}} with less verbose ({{getHostnameAndIP}} + UUID) implementation, and keep the current one for occasional usage as {{toDebugString}}.  Need to be verify if this causes and regressions.",
      "HDDS",
      "Resolved",
      3,
      3,
      1699,
      "pull-request-available"
    ],
    [
      13261237,
      "Avoid buffer copying in GrpcReplicationService",
      "In GrpcOutputStream, it writes data to a ByteArrayOutputStream and copies them to a ByteString.",
      "HDDS",
      "Resolved",
      3,
      4,
      1699,
      "performance, pull-request-available"
    ],
    [
      13316901,
      "Ratis config key mismatch",
      "Some of the Ratis configurations in integration tests are not applied due to mismatch in config keys.\n # [Ratis|https://github.com/apache/incubator-ratis/blob/master/ratis-client/src/main/java/org/apache/ratis/client/RaftClientConfigKeys.java#L41-L53]: {{raft.client.rpc.watch.request.timeout}}\n [Ozone|https://github.com/apache/hadoop-ozone/blob/926048403d115ddcb59ff130e5c46e518874b8aa/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestCommitWatcher.java#L119-L122]: {{raft.client.watch.request.timeout}}\n # [Ratis|https://github.com/apache/incubator-ratis/blob/4db4f804aa90f9900cda08c79b54a45f80f4213b/ratis-server/src/main/java/org/apache/ratis/server/RaftServerConfigKeys.java#L470-L473]: {{raft.server.notification.no-leader.timeout}}\n [Ozone|https://github.com/apache/hadoop-ozone/blob/926048403d115ddcb59ff130e5c46e518874b8aa/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/conf/DatanodeRatisServerConfig.java#L42]: {{raft.server.Notification.no-leader.timeout}}",
      "HDDS",
      "Resolved",
      3,
      1,
      1699,
      "pull-request-available"
    ],
    [
      13437800,
      "Bump Jackson Databind",
      "Upgrade Jackson Databind to latest.",
      "HDDS",
      "Resolved",
      3,
      3,
      1699,
      "pull-request-available"
    ],
    [
      13562953,
      "Clean up test dependencies",
      " * Provide the same set of basic test dependencies for all modules.\n * Remove leftover dependencies (mostly related to JUnit4).\n",
      "HDDS",
      "Resolved",
      3,
      7,
      1699,
      "pull-request-available"
    ],
    [
      13590128,
      "Log for EC reconstruction command lists the missing indexes as ASCII control characters",
      "Logs for EC reconstruction command lists the missing indexes as ASCII control characters like ^A ^B.\n\n\u00a0\n{noformat}\n2024-08-27 05:28:34,857 INFO [node1-UnderReplicatedProcessor]-org.apache.hadoop.hdds.scm.container.replication.ReplicationManager: Sending command [reconstructECContainersCommand: containerID: 15001, replicationConfig: EC{rs-3-2-1024k}, sources: [693753b9-cfb5-4bcc-9863-273cf3d32d05 replicaIndex: 3, 20213e45-1d8c-4224-96be-83d2c7f85c00 replicaIndex: 4, d6d0d2b5-dab9-48ec-8866-54b3d70f8b37 replicaIndex: 5], targets: [dd2d9383-a4c8-4aa9-9290-7d5494618a3a, 9b08f05b-2cbb-4bba-bcf5-1c1bd5d1ac01], missingIndexes: ^A^B] for container ContainerInfo{id=#15001, state=CLOSED, stateEnterTime=2024-08-27T05:26:28.228489Z, pipelineID=PipelineID=2b855dc6-d3fb-47a4-87d2-4b4b525bbae3, owner=ozone1724217699} to dd2d9383-a4c8-4aa9-9290-7d5494618a3a with datanode deadline 1724737384857 and scm deadline 1724737414857{noformat}\nThis is due to the change made as part of HDDS-10756",
      "HDDS",
      "Resolved",
      3,
      1,
      1699,
      "pull-request-available"
    ],
    [
      13316718,
      "Avoid HddsProtos.PipelineID#toString",
      "{{PipelineID}} was recently changed to have integer-based ID in addition to the string ID.  Now log messages including {{PipelineID}} span multiple lines:\n\n{code:title=https://github.com/elek/ozone-build-results/blob/92d31c9b58065b37a371c71c97b346f99163318d/2020/07/11/1626/acceptance/docker-ozone-ozone-freon-scm.log#L218-L223}\ndatanode_1  | 2020-07-11 13:07:00,540 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE #id: \"8101dcbf-1a28-4f20-863a-0616b4e4bc4b\"\ndatanode_1  | uuid128 {\ndatanode_1  |   mostSigBits: -9150790254504423648\ndatanode_1  |   leastSigBits: -8774694229384053685\ndatanode_1  | }\ndatanode_1  | .\n{code}",
      "HDDS",
      "Resolved",
      3,
      1,
      1699,
      "pull-request-available"
    ],
    [
      13291773,
      "Intermittent failure in TestReconWithOzoneManager due to BindException",
      "TestReconWithOzoneManager may fail with BindException:\n\n{code:title=https://github.com/apache/hadoop-ozone/pull/677/checks?check_run_id=507376007}\nTests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 19.707 s <<< FAILURE! - in org.apache.hadoop.ozone.recon.TestReconWithOzoneManager\norg.apache.hadoop.ozone.recon.TestReconWithOzoneManager  Time elapsed: 19.706 s  <<< ERROR!\npicocli.CommandLine$ExecutionException: Error while calling command (org.apache.hadoop.ozone.recon.ReconServer@23f74a49): java.net.BindException: Port in use: 0.0.0.0:36263\n\t...\n\tat org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:534)\n\tat org.apache.hadoop.ozone.recon.TestReconWithOzoneManager.init(TestReconWithOzoneManager.java:109)\n\t...\nCaused by: java.net.BindException: Port in use: 0.0.0.0:36263\n\tat org.apache.hadoop.hdds.server.http.HttpServer2.constructBindException(HttpServer2.java:1200)\n\tat org.apache.hadoop.hdds.server.http.HttpServer2.bindForSinglePort(HttpServer2.java:1222)\n\tat org.apache.hadoop.hdds.server.http.HttpServer2.openListeners(HttpServer2.java:1281)\n\tat org.apache.hadoop.hdds.server.http.HttpServer2.start(HttpServer2.java:1136)\n\tat org.apache.hadoop.hdds.server.http.BaseHttpServer.start(BaseHttpServer.java:252)\n\tat org.apache.hadoop.ozone.recon.ReconServer.start(ReconServer.java:128)\n\tat org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:106)\n\tat org.apache.hadoop.ozone.recon.ReconServer.call(ReconServer.java:50)\n\tat picocli.CommandLine.execute(CommandLine.java:1173)\n\t... 27 more\n{code}\n\n{code:title=test output}\n2020-03-14 06:17:08,677 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(284)) - HTTP server of ozoneManager listening at http://0.0.0.0:36263\n...\n2020-03-14 06:17:11,589 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(170)) - Starting Web-server for recon at: http://0.0.0.0:36263\n...\n2020-03-14 06:17:12,756 [main] INFO  recon.ReconServer (ReconServer.java:start(125)) - Starting Recon server\n2020-03-14 06:17:12,757 [main] INFO  http.HttpServer2 (HttpServer2.java:start(1139)) - HttpServer.start() threw a non Bind IOException\njava.net.BindException: Port in use: 0.0.0.0:36263\n...\n{code}",
      "HDDS",
      "Resolved",
      4,
      1,
      1699,
      "pull-request-available"
    ],
    [
      13566481,
      "Refactor some constructors in SCM to avoid too many parameters",
      "{{SCMContext}} is created using builder.  To avoid too many parameters in the constructor, it should be changed to assign members directly from the {{Builder}} object.\n\nApply similar change to some other classes in SCM, too.",
      "HDDS",
      "Resolved",
      3,
      7,
      1699,
      "pull-request-available"
    ],
    [
      13471167,
      "Update Contributing guide",
      "The goal is to fix some outdated items in the contributors' guide, as well as make some minor improvements.",
      "HDDS",
      "Resolved",
      3,
      4,
      1699,
      "pull-request-available"
    ],
    [
      13290498,
      "Unit check fails to execute insight and mini-chaos-tests modules",
      "This was observed in unit check run for 0.5.0 RC.\n\n{code:title=https://github.com/apache/hadoop-ozone/runs/490978126?check_suite_focus=true}\n2020-03-06T19:13:08.6122969Z [ERROR] Failed to execute goal on project hadoop-ozone-insight: Could not resolve dependencies for project org.apache.hadoop:hadoop-ozone-insight:jar:0.5.0-beta: Could not find artifact org.apache.hadoop:hadoop-ozone-integration-test:jar:tests:0.5.0-beta in apache.snapshots.https (https://repository.apache.org/content/repositories/snapshots) -> [Help 1]\n2020-03-06T19:13:08.6180318Z [ERROR] Failed to execute goal on project mini-chaos-tests: Could not resolve dependencies for project org.apache.hadoop:mini-chaos-tests:jar:0.5.0-beta: Failure to find org.apache.hadoop:hadoop-ozone-integration-test:jar:tests:0.5.0-beta in https://repository.apache.org/content/repositories/snapshots was cached in the local repository, resolution will not be reattempted until the update interval of apache.snapshots.https has elapsed or updates are forced -> [Help 1]\n{code}\n\nUnit check skips {{integration-test}}, but these 2 modules depend on it.",
      "HDDS",
      "Resolved",
      3,
      1,
      1699,
      "pull-request-available"
    ],
    [
      13538788,
      "Let reconfiguration handler update reconfigurable config objects",
      "HDDS-8668 implements reconfigurable config objects.  HDDS-8702 creates a dedicated reconfiguration handler, which handles individual reconfigurable properties so far.  The goal of this task is to allow registering config objects with the reconfiguration handler.",
      "HDDS",
      "Resolved",
      3,
      7,
      1699,
      "pull-request-available"
    ],
    [
      13250198,
      "StackOverflowError in OzoneClientInvocationHandler",
      "Happens if log level for {{org.apache.hadoop.ozone.client}} is set to TRACE.\n\n{code}\nSLF4J: Failed toString() invocation on an object of type [com.sun.proxy.$Proxy85]\nReported exception:\njava.lang.StackOverflowError\n...\n\tat org.slf4j.impl.Log4jLoggerAdapter.trace(Log4jLoggerAdapter.java:156)\n\tat org.apache.hadoop.ozone.client.OzoneClientInvocationHandler.invoke(OzoneClientInvocationHandler.java:51)\n\tat com.sun.proxy.$Proxy85.toString(Unknown Source)\n\tat org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:299)\n\tat org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:271)\n\tat org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:233)\n\tat org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:173)\n\tat org.slf4j.helpers.MessageFormatter.format(MessageFormatter.java:151)\n\tat org.slf4j.impl.Log4jLoggerAdapter.trace(Log4jLoggerAdapter.java:156)\n\tat org.apache.hadoop.ozone.client.OzoneClientInvocationHandler.invoke(OzoneClientInvocationHandler.java:51)\n\tat com.sun.proxy.$Proxy85.toString(Unknown Source)\n...\n{code}",
      "HDDS",
      "Resolved",
      5,
      1,
      1699,
      "pull-request-available"
    ]
  ]
}