{
  "columns": [
    "模型",
    "關鍵創新",
    "方法論",
    "主要結果"
  ],
  "data": [
    [
      "Timer",
      "預訓練的僅解碼器Transformer",
      "異構數據的統一序列格式",
      "僅使用1-5%數據即展現強大的少樣本性能"
    ],
    [
      "MOMENT",
      "開源基礎模型系列",
      "多數據集訓練策略",
      "優越的有限監督性能"
    ],
    [
      "TimeMixer",
      "多尺度MLP架構",
      "用於時間模式的可分解混合區塊",
      "在18個基準測試中達到SOTA"
    ],
    [
      "TimesNet",
      "多週期性分析",
      "將1D轉換為2D以處理時間模式",
      "在5個主要任務中實現統一性能"
    ],
    [
      "PatchTST",
      "基於分塊的時間序列處理",
      "通道獨立的Transformer",
      "在長期預測中，MSE降低21%"
    ]
  ]
}