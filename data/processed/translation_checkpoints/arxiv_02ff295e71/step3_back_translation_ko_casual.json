{
  "columns": [
    "Name",
    "Method",
    "Key Idea",
    "Performance"
  ],
  "data": [
    [
      "StockFormer",
      "A transformer-based model that uses historical stock prices and news data",
      "A three-stage framework that uses technical indicators and fundamental analysis",
      "Return: +40.3%, SR: +22.7% vs SAC"
    ],
    [
      "MacMic",
      "Macro-micro dual-scale modeling",
      "Reinforcement learning using HMM for macroeconomic analysis",
      "Improved performance in both long-term and short-term trading"
    ],
    [
      "IMM",
      "A hybrid model that combines fundamental analysis and technical indicators",
      "A dynamic portfolio optimization using deep learning and market sentiment",
      "Outperforms in volatile markets with high accuracy"
    ],
    [
      "EarnHFT",
      "High-frequency trading using deep learning and market data",
      "Combines Q-learning with neural networks for high-speed decision-making",
      "SOTA performance in HFT with +30% return"
    ],
    [
      "MacroHFT",
      "High-frequency trading using macroeconomic indicators",
      "Analyzes macroeconomic trends and market volatility",
      "Outperforms in HFT with high return and low risk"
    ],
    [
      "DRPO",
      "A deep reinforcement learning approach for portfolio optimization",
      "A policy optimization method using deep learning",
      "Execution latency of 415ms with high accuracy"
    ],
    [
      "CPPI-MADDPG",
      "A multi-agent deep deterministic policy gradient approach",
      "A multi-agent reinforcement learning framework for portfolio management",
      "AR: 9.68%, SR: 2.18 (SZSE)"
    ],
    [
      "HRT",
      "Hybrid trading strategy",
      "A combination of PPO and DDPG for market conditions",
      "Outperforms in S&P500 with consistent performance"
    ],
    [
      "TRR",
      "LLM-based trading rule generation",
      "Four-stage rule generation process",
      "Improved performance of the trading rules"
    ]
  ]
}