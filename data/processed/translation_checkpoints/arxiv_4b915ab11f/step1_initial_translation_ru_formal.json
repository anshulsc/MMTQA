{
  "columns": [],
  "data": [
    [
      "Предобученная LLM",
      "Размер корпуса",
      "Бюджет обучения (A100·часы)",
      "Архитектура модели"
    ],
    [
      "BloomBergGPT",
      "363B Финансовые токены + 345B публичных токенов",
      "1300000",
      "50B-BLOOM"
    ],
    [
      "XuanYuan2.0",
      "366B для предобучения + 13B для тонкой настройки",
      "Не опубликовано",
      "176B-BLOOM"
    ],
    [
      "Fin-T5",
      "80B Финансовые токены",
      "Дни/недели",
      "770M-T5"
    ]
  ]
}