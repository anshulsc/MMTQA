{
  "columns": [],
  "data": [
    [
      "โมเดล LLM ที่ถูกเทรนไว้ล่วงหน้า",
      "ขนาดของคอร์ปัส",
      "งบประมาณการเทรน (A100·ชั่วโมง)",
      "สถาปัตยกรรมของโมเดล"
    ],
    [
      "BloomBergGPT",
      "โทเค็นการเงิน 363B + โทเค็นสาธารณะ 345B",
      "1300000",
      "50B-BLOOM"
    ],
    [
      "XuanYuan2.0",
      "366B สำหรับการเทรนเบื้องต้น + 13B สำหรับการเทรนเพิ่มเติม",
      "ยังไม่เปิดเผย",
      "176B-BLOOM"
    ],
    [
      "Fin-T5",
      "โทเค็นการเงิน 80B",
      "วัน/สัปดาห์",
      "770M-T5"
    ]
  ]
}