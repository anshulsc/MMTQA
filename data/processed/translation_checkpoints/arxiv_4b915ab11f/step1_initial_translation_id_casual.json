{
  "columns": [],
  "data": [
    [
      "LLM yang sudah dilatih sebelumnya",
      "Ukuran kumpulan data",
      "Anggaran pelatihan (A100Â·jam)",
      "Arsitektur model"
    ],
    [
      "BloomBergGPT",
      "363B token keuangan + 345B token umum",
      "1300000",
      "50B-BLOOM"
    ],
    [
      "XuanYuan2.0",
      "366B untuk pelatihan awal + 13B untuk pelatihan lanjutan",
      "Belum dirilis",
      "176B-BLOOM"
    ],
    [
      "Fin-T5",
      "80B token keuangan",
      "Hari/minggu",
      "770M-T5"
    ]
  ]
}