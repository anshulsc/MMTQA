{
  "columns": [
    "Model",
    "Key Invention",
    "Methodology",
    "Key Results"
  ],
  "data": [
    [
      "TiMER",
      "Pre-trained Decoder-Only Transformer",
      "Unified sequence format for various data",
      "Strong few-shot performance with 1-5% data"
    ],
    [
      "MoMENT",
      "Open-source foundation model family",
      "Multi-dataset training strategy",
      "Excellent limited-observation performance"
    ],
    [
      "TimeMixer",
      "Multiscale MLP architecture",
      "Analyzable mixing block for temporal patterns",
      "SOTA (State-of-the-Art) results on 18 benchmarks"
    ],
    [
      "TimeSNet",
      "Multi-periodicity analysis",
      "1D to 2D transformation for temporal patterns",
      "Unified performance on 5 major tasks"
    ],
    [
      "PatchTST",
      "Patch-based time series processing",
      "Channel-independent Transformer",
      "21% MSE reduction in long-term forecasting"
    ]
  ]
}