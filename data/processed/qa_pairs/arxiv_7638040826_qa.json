[
  {
    "question_id": "arxiv_7638040826_001",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "Which dataset specifically focuses on the language used by a central bank to understand monetary policy's influence, and who published it?",
    "answer": [
      [
        "Trillion Dollar Words",
        "Shah et al. (2023a)"
      ]
    ],
    "evidence_cells": [
      "A5",
      "B5",
      "C5"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_002",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "List all resources published after 2020 that are explicitly described as being human-annotated or written by experts.",
    "answer": [
      [
        "SEntFiN 1.0"
      ],
      [
        "Gold Commodity Dataset"
      ],
      [
        "FINQA"
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "A7",
      "B7",
      "C7",
      "A10",
      "B10",
      "C10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_003",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "Based on the publication dates, describe the evolution of focus in these financial datasets from the early 2010s to the 2020s.",
    "answer": [
      [
        "The datasets show an evolution from foundational sentiment analysis in the early 2010s to more complex, specialized tasks in the 2020s. Early resources like SentiWordNet (2010) and Financial Phrase Bank (2014) dealt with general word/phrase sentiment. In contrast, resources from the 2020s like SEntFiN 1.0 (entity-specific sentiment), REFinD (relation extraction), and FINQA (deep reasoning) tackle more granular and complex NLP problems, indicating a maturation of the field towards more nuanced financial text understanding."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "B2",
      "C2",
      "B4",
      "C4",
      "B6",
      "C6",
      "B10",
      "C10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_004",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "How many of the listed resources focus primarily on sentiment analysis (assigning positive, negative, or neutral labels)?",
    "answer": [
      [
        "4"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A2",
      "B2",
      "A3",
      "B3",
      "A4",
      "B4"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_7638040826_005",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "Which resource is an outlier in its specific geographical focus compared to the others?",
    "answer": [
      [
        "Financial Phrase Bank"
      ]
    ],
    "evidence_cells": [
      "A2",
      "B2"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_7638040826_006",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "What percentage of the datasets listed were published in 2023?",
    "answer": [
      [
        "40%"
      ]
    ],
    "evidence_cells": [
      "C5",
      "C6",
      "C8",
      "C9"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_7638040826_007",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "If the 'SEntFiN 1.0' dataset were removed, what would be the most recently published resource focused on analyzing news headlines?",
    "answer": [
      [
        "MULTIFIN"
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "A7",
      "B7",
      "C7",
      "A9",
      "B9",
      "C9"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_008",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "Which author or author group has contributed the highest number of distinct resources in this list?",
    "answer": [
      [
        "Shah et al."
      ]
    ],
    "evidence_cells": [
      "C5",
      "C8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_009",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "Compare the primary NLP task addressed by 'FiNER' with that of 'REFinD'.",
    "answer": [
      [
        "'FiNER' is designed for a foundational NLP task, Named Entity Recognition (NER), which involves identifying and classifying entities like financial companies. 'REFinD' addresses a more complex, subsequent task of relation extraction, aiming to identify the relationships between already identified entities (e.g., person-title, org-money). Therefore, FiNER focuses on identifying the 'actors' while REFinD focuses on identifying their 'interactions'."
      ]
    ],
    "evidence_cells": [
      "B6",
      "B8"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_010",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "Based on the descriptions, is there a correlation between datasets focusing on 'headlines' and the recency of their publication year? Explain your reasoning.",
    "answer": [
      [
        "Yes, there appears to be a positive correlation. All three datasets that explicitly mention 'headlines' in their descriptions (SEntFiN 1.0, Gold Commodity Dataset, and MULTIFIN) were published in 2021 or later. Datasets published earlier, in the 2010s, do not mention this specific focus. This suggests a growing research interest in analyzing the concise and impactful language of financial news headlines in recent years."
      ]
    ],
    "evidence_cells": [
      "B4",
      "C4",
      "B7",
      "C7",
      "B9",
      "C9"
    ],
    "reasoning_category": "Correlation Inference"
  }
]