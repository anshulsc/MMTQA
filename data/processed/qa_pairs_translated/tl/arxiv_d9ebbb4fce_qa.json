[
  {
    "question_id": "arxiv_d9ebbb4fce_001",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Aling modelo ang tahasang binanggit na nakamit ang State-of-the-Art (SOTA) performance sa maraming benchmark?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_002",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Ilan sa mga nakalistang modelo ang gumagamit ng teknolohiyang 'transformer' sa kanilang pangunahing inobasyon o pamamaraan?",
    "answer": [
      [
        "3"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_003",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Ano ang pangunahing inobasyon ng modelong gumagamit ng mga estratehiya sa pagsasanay na multi-dataset?",
    "answer": [
      [
        "Open-source foundation model family"
      ]
    ],
    "evidence_cells": [
      "B2",
      "C2"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_004",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Aling modelo ang gumagamit ng pagbabago ng 1D temporal data tungo sa 2D representation para sa pagsusuri ng mga pattern bilang bahagi ng methodology nito?",
    "answer": [
      [
        "TimesNet"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_005",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Ilista ang mga modelong inilalarawan bilang 'foundation model' o gumagamit ng 'pre-trained' na pamamaraan sa kanilang inobasyon.",
    "answer": [
      [
        "Timer"
      ],
      [
        "MOMENT"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A2",
      "B2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_006",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Ilang porsyento ng mga modelo sa listahang ito ang gumagamit ng arkitektura na nakabatay sa mga transformer?",
    "answer": [
      [
        "60%"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5",
      "A1",
      "A2",
      "A3",
      "A4",
      "A5"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_007",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Kung ang pangunahing limitasyon ng isang research team ay napakaliit na dami ng training data (1-5%), aling modelo ang nagmumungkahi ng mga resulta na ito ang magiging pinakaepektibong pagpipilian?",
    "answer": [
      [
        "Timer"
      ]
    ],
    "evidence_cells": [
      "A1",
      "D1"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_008",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "open_ended_reasoning",
    "question": "Batay sa talahanayan, anong relasyon ang maaaring mahinuha sa pagitan ng metodolohiya ng isang modelo at ng pangunahing mga resulta nito, lalo na tungkol sa mga transformer architecture?",
    "answer": [
      [
        "Ipinapahiwatig ng datos ang isang ugnayan sa pagitan ng paggamit ng mga arkitekturang batay sa transformer at ang pagkamit ng matatag na pagganap sa mga tiyak at mapaghamong sitwasyon. Halimbawa, ang pre-trained decoder-only transformer ng Timer ay nagreresulta sa matatag na few-shot performance, habang ang channel-independent transformer ng PatchTST ay nagdudulot ng makabuluhang pagbaba ng MSE sa long-term forecasting. Ipinahihiwatig nito na ang mga metodolohiyang batay sa transformer ay partikular na epektibo para sa mga gawain na nangangailangan ng kahusayan sa datos (few-shot learning) o pagkuha ng mga long-range dependencies (long-term forecasting)."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "D1",
      "B5",
      "C5",
      "D5"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_009",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Aling column ang naglalaman ng impormasyon na naglalarawan sa pangunahing pamamaraan ng algorithm o istruktura ng bawat modelo?",
    "answer": [
      [
        "Methodology"
      ]
    ],
    "evidence_cells": [
      "C1",
      "C2",
      "C3",
      "C4",
      "C5"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_010",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Aling modelo ang may pangunahing resulta na namumukod-tangi sa pamamagitan ng pagbibigay ng isang tiyak, kuwantitatibong sukatan ng pagganap sa halip na isang kwalitatibong paglalarawan tulad ng 'malakas' o 'superyor' na pagganap?",
    "answer": [
      [
        "PatchTST"
      ]
    ],
    "evidence_cells": [
      "A5",
      "D1",
      "D2",
      "D3",
      "D4",
      "D5"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_011",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Aling modelo ang nahigitan ang lahat ng modelo sa 18 benchmark datasets?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  }
]