[
  {
    "question_id": "arxiv_e9fef14615_001",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Какая модель достигла наивысшего показателя F1 на наборе данных 'ccfraud'?",
    "answer": [
      [
        "Gemini"
      ]
    ],
    "evidence_cells": [
      "A4",
      "E4",
      "C4",
      "D4",
      "F4",
      "G4",
      "H4",
      "I4",
      "J4",
      "K4",
      "L4",
      "M4",
      "N4",
      "O4",
      "E10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_002",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Какова средняя оценка точности ('Acc') для модели 'GPT 4' по всем наборам данных, где использовалась эта метрика?",
    "answer": [
      [
        "0.543"
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B5",
      "D5",
      "B9",
      "D9",
      "D10"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_e9fef14615_003",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Определите набор данных, в котором \"FinMA 7B\" показал свой наивысший результат, а затем перечислите модель(и), получившую нулевой результат в той же задаче.",
    "answer": [
      [
        "taiwan",
        "Falcon 7B"
      ]
    ],
    "evidence_cells": [
      "A11",
      "I11",
      "L11",
      "I1",
      "I2",
      "I3",
      "I4",
      "I5",
      "I6",
      "I7",
      "I8",
      "I9",
      "I12",
      "I10",
      "L10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_004",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "На наборе данных 'TSA' какая модель демонстрирует наибольшее снижение производительности по сравнению с моделью, указанной в столбце непосредственно слева от нее, и каково значение этого снижения?",
    "answer": [
      [
        "FinGPT 7B-lora",
        "0.80"
      ]
    ],
    "evidence_cells": [
      "A3",
      "I3",
      "J3",
      "I10",
      "J10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_005",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Укажите все наборы данных, в которых модель «Gemini» достигла результата 0,90 или выше, И модель «Chat GPT» показала результат 0,20 или ниже.",
    "answer": [
      [
        "ccfraud"
      ],
      [
        "taiwan"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4",
      "E4",
      "A11",
      "C11",
      "E11",
      "C10",
      "E10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_006",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Для набора данных 'LendingClub', какой процент совокупного результата от всех моделей приходится на три лучшие модели для данной задачи? Округлите до одного десятичного знака.",
    "answer": [
      [
        "41.3%"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C6",
      "D6",
      "E6",
      "F6",
      "G6",
      "H6",
      "I6",
      "J6",
      "K6",
      "L6",
      "M6",
      "N6",
      "O6"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_e9fef14615_007",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Если бы все показатели для модели 'LLaMA2 70B' были увеличены на 10%, каков был бы его новый средний показатель по всем оцененным задачам? Округлите до трех знаков после запятой.",
    "answer": [
      [
        "0.354"
      ]
    ],
    "evidence_cells": [
      "G1",
      "G2",
      "G3",
      "G4",
      "G5",
      "G6",
      "G7",
      "G8",
      "G9",
      "G11",
      "G12",
      "G10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_008",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Проанализируйте задачи, измеряемые метриками 'F1' или 'MicroF1'. Существует ли устойчивая зависимость производительности между моделями 'GPT 4' и 'Gemini'? Объясните ваш ответ.",
    "answer": [
      [
        "Сильной положительной корреляции нет, но существует явная иерархия производительности. В задачах, основанных на метрике F1, Gemini последовательно превосходит или соответствует GPT 4. Для наборов данных 'ccfraud' и 'taiwan' показатели Gemini (0,90 и 0,95) значительно выше, чем у GPT 4 (0,55 для обоих). Для 'LendingClub' Gemini (0,65) по-прежнему умеренно выше, чем GPT 4 (0,55). Только в наборе данных 'MLESG' их показатели почти идентичны (0,35 против 0,34). Это предполагает, что, хотя их производительность не тесно коррелирует, Gemini в целом является лучшей моделью для этих конкретных задач, измеряемых метрикой F1."
      ]
    ],
    "evidence_cells": [
      "B4",
      "D4",
      "E4",
      "B6",
      "D6",
      "E6",
      "B11",
      "D11",
      "E11",
      "B12",
      "D12",
      "E12",
      "D10",
      "E10"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_e9fef14615_009",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "На основании данных о производительности, какие два набора данных показывают нулевые показатели по всем протестированным моделям, что указывает на возможный сбой оценки или задачу, которую ни одна модель не смогла выполнить?",
    "answer": [
      [
        "FNXL"
      ],
      [
        "ECTSUM"
      ]
    ],
    "evidence_cells": [
      "A7",
      "C7",
      "D7",
      "E7",
      "F7",
      "G7",
      "H7",
      "I7",
      "J7",
      "K7",
      "L7",
      "M7",
      "N7",
      "O7",
      "A8",
      "C8",
      "D8",
      "E8",
      "F8",
      "G8",
      "H8",
      "I8",
      "J8",
      "K8",
      "L8",
      "M8",
      "N8",
      "O8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_010",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Для модели 'Gemini' какой показатель набора данных представляет собой наиболее значительный положительный выброс производительности и почему?",
    "answer": [
      [
        "Показатель для набора данных 'taiwan' (0.95) является наиболее значительным положительным выбросом для модели Gemini. Расчет среднего значения ненулевых показателей Gemini дает примерно 0.615. Показатель 0.95 является самым высоким значением и наиболее удаленным от этого среднего по сравнению со всеми другими показателями. Такая необычно высокая производительность предполагает, что модель Gemini исключительно хорошо подходит для задачи, определяемой набором данных 'taiwan' и метрикой 'F1', или что сама задача оказалась значительно проще для этой модели, чем для других."
      ]
    ],
    "evidence_cells": [
      "A11",
      "B11",
      "E11",
      "E1",
      "E2",
      "E3",
      "E4",
      "E5",
      "E6",
      "E7",
      "E8",
      "E9",
      "E12",
      "E10"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_e9fef14615_011",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Какая модель демонстрирует устойчивую обобщающую способность как в задачах извлечения сущностей (NER, FINER-ORD), так и в задачах классификации тональности (FPB, SC)?",
    "answer": [
      [
        "GPT-4 стабильно показывает хорошие результаты как на наборах данных для извлечения сущностей, так и для классификации тональности, достигая высоких показателей EntityF1 и F1 по сравнению с другими моделями."
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "D2",
      "A3",
      "C3",
      "D3",
      "A5",
      "J5",
      "A9",
      "J9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]