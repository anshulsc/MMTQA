[
  {
    "question_id": "arxiv_4b915ab11f_001",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Какая модель из перечисленных использует самую большую базовую архитектуру по количеству параметров?",
    "answer": [
      [
        "XuanYuan2.0"
      ]
    ],
    "evidence_cells": [
      "A2",
      "D1",
      "D2",
      "D3"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_4b915ab11f_002",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Каково общее количество токенов в корпусе, использованном для обучения BloomBergGPT?",
    "answer": [
      [
        "708B"
      ]
    ],
    "evidence_cells": [
      "B1"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_4b915ab11f_003",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Каков бюджет обучения модели, построенной на архитектуре T5?",
    "answer": [
      [
        "Days/weeks"
      ]
    ],
    "evidence_cells": [
      "A3",
      "C3",
      "D3"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_4b915ab11f_004",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Для модели, в которой указан двухэтапный процесс подготовки данных, каков был размер корпуса для этапа предварительного обучения?",
    "answer": [
      [
        "366B"
      ]
    ],
    "evidence_cells": [
      "B2"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_4b915ab11f_005",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Укажите LLM, которая использует архитектуру на основе BLOOM и имеет опубликованный бюджет обучения, указанный в часах A100.",
    "answer": [
      [
        "BloomBergGPT"
      ]
    ],
    "evidence_cells": [
      "A1",
      "C1",
      "D1",
      "C2",
      "D2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_4b915ab11f_006",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Какой процент общедоступных токенов составляет общий тренировочный корпус BloomBergGPT?",
    "answer": [
      [
        "48.73%"
      ]
    ],
    "evidence_cells": [
      "B1"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_4b915ab11f_007",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "open_ended_reasoning",
    "question": "Если бы бюджет обучения XuanYuan2.0 был раскрыт как 2 500 000 часов A100, как бы это повлияло на рейтинг моделей по бюджету обучения?",
    "answer": [
      [
        "В настоящее время BloomBergGPT имеет единственный указанный числовой бюджет (1 300 000 часов A100), что ставит его на первое место. Если бы бюджет XuanYuan2.0 составил 2 500 000 часов A100, он стал бы моделью с самым высоким известным бюджетом обучения, превзойдя BloomBergGPT. Новый рейтинг моделей с числовыми бюджетами выглядел бы так: 1. XuanYuan2.0 (2 500 000) и 2. BloomBergGPT (1 300 000)."
      ]
    ],
    "evidence_cells": [
      "A1",
      "C1",
      "A2",
      "C2"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_4b915ab11f_008",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "open_ended_reasoning",
    "question": "Существует ли последовательная корреляция между количеством параметров архитектуры модели и общим размером ее обучающего корпуса на основе этих данных?",
    "answer": [
      [
        "Нет, последовательной положительной корреляции в данных не наблюдается. Например, XuanYuan2.0 имеет гораздо большую архитектуру (176 млрд параметров) по сравнению с BloomBergGPT (50 млрд параметров), тем не менее, он был обучен на меньшем корпусе (379 млрд токенов против 708 млрд токенов). Это говорит о том, что большая модель не обязательно требует большего обучающего корпуса согласно этому набору данных."
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B2",
      "D2"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_4b915ab11f_009",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Какой столбец данных демонстрирует наибольшее разнообразие в формате данных, содержащий большое целое число, строку, являющуюся коммерческой тайной, и диапазон, основанный на времени?",
    "answer": [
      [
        "Training budget (A100·hours)"
      ]
    ],
    "evidence_cells": [
      "C1",
      "C2",
      "C3"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_4b915ab11f_010",
    "table_id": "arxiv_4b915ab11f",
    "question_type": "value",
    "question": "Бюджет на обучение какой модели значительно превышает бюджеты других моделей, по которым есть информация?",
    "answer": [
      [
        "BloomBergGPT"
      ]
    ],
    "evidence_cells": [
      "A1",
      "C1",
      "C2",
      "C3"
    ],
    "reasoning_category": "Outlier Detection"
  }
]