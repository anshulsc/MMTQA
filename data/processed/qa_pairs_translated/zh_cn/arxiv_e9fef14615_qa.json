[
  {
    "question_id": "arxiv_e9fef14615_001",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "在 'ccfraud' 数据集上，哪个模型的 F1 分数最高？",
    "answer": [
      [
        "Gemini"
      ]
    ],
    "evidence_cells": [
      "A4",
      "E4",
      "C4",
      "D4",
      "F4",
      "G4",
      "H4",
      "I4",
      "J4",
      "K4",
      "L4",
      "M4",
      "N4",
      "O4",
      "E10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_002",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "在所有使用此度量标准的数据集中，“GPT 4”模型的平均准确率（'Acc'）得分是多少？",
    "answer": [
      [
        "0.543"
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B5",
      "D5",
      "B9",
      "D9",
      "D10"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_e9fef14615_003",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "找出“FinMA 7B”得分最高的那个数据集，然后列出在该相同任务上得分零的模型的名称。",
    "answer": [
      [
        "taiwan",
        "Falcon 7B"
      ]
    ],
    "evidence_cells": [
      "A11",
      "I11",
      "L11",
      "I1",
      "I2",
      "I3",
      "I4",
      "I5",
      "I6",
      "I7",
      "I8",
      "I9",
      "I12",
      "I10",
      "L10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_004",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "在“TSA”数据集上，哪个模型的性能下降幅度最大（相对于其左侧列的模型），以及下降的值是多少？",
    "answer": [
      [
        "FinGPT 7B-lora",
        "0.80"
      ]
    ],
    "evidence_cells": [
      "A3",
      "I3",
      "J3",
      "I10",
      "J10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_005",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "找出 'Gemini' 模型得分大于等于 0.90 且 'Chat GPT' 模型得分小于等于 0.20 的所有数据集。",
    "answer": [
      [
        "ccfraud"
      ],
      [
        "taiwan"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4",
      "E4",
      "A11",
      "C11",
      "E11",
      "C10",
      "E10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_006",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "对于“LendingClub”数据集，所有模型累积得分中有多少百分比可以归因于该任务表现最佳的三种模型？保留一位小数。",
    "answer": [
      [
        "41.3%"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C6",
      "D6",
      "E6",
      "F6",
      "G6",
      "H6",
      "I6",
      "J6",
      "K6",
      "L6",
      "M6",
      "N6",
      "O6"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_e9fef14615_007",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "如果 'LLaMA2 70B' 模型的所有得分都增加 10%，那么它在所有评估任务上的新平均得分是多少？四舍五入到三位小数。",
    "answer": [
      [
        "0.354"
      ]
    ],
    "evidence_cells": [
      "G1",
      "G2",
      "G3",
      "G4",
      "G5",
      "G6",
      "G7",
      "G8",
      "G9",
      "G11",
      "G12",
      "G10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_008",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "检查以“F1”或“MicroF1”指标衡量的任务。在“GPT 4”和“Gemini”模型之间是否存在一致的表现关系？请解释你的理由。",
    "answer": [
      [
        "没有很强的正相关性，但存在明确的表现层级。在基于 F1 的任务上，Gemini 始终优于或匹配 GPT 4。对于 'ccfraud' 和 'taiwan' 数据集，Gemini 的分数（分别为 0.90 和 0.95）远高于 GPT 4 的分数（两者均为 0.55）。对于 'LendingClub'，Gemini (0.65) 仍然明显高于 GPT 4 (0.55)。仅在 'MLESG' 数据集上，它们的分数几乎相同 (0.35 vs 0.34)。这表明，虽然它们的表现并非严格相关，但对于这些特定的 F1 测量任务，Gemini 通常是一个更优越的模型。"
      ]
    ],
    "evidence_cells": [
      "B4",
      "D4",
      "E4",
      "B6",
      "D6",
      "E6",
      "B11",
      "D11",
      "E11",
      "B12",
      "D12",
      "E12",
      "D10",
      "E10"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_e9fef14615_009",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "根据性能数据，哪两个数据集在所有测试模型中的得分均为零，这表明可能存在评估失败或模型无法完成的任务？",
    "answer": [
      [
        "FNXL"
      ],
      [
        "ECTSUM"
      ]
    ],
    "evidence_cells": [
      "A7",
      "C7",
      "D7",
      "E7",
      "F7",
      "G7",
      "H7",
      "I7",
      "J7",
      "K7",
      "L7",
      "M7",
      "N7",
      "O7",
      "A8",
      "C8",
      "D8",
      "E8",
      "F8",
      "G8",
      "H8",
      "I8",
      "J8",
      "K8",
      "L8",
      "M8",
      "N8",
      "O8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_010",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "对于‘Gemini’模型，哪个数据集的分数代表了最显著的正面异常值，为什么？",
    "answer": [
      [
        "‘taiwan’数据集（0.95）的分数是Gemini模型最显著的正面异常值。计算Gemini的非零分数的平均值约为0.615。分数0.95是所有分数中最高的值，并且与这个平均值的距离最远。这种异常高的表现表明Gemini模型非常适合‘taiwan’数据集和‘F1’指标定义的任务，或者该任务本身对于该模型比其他模型要容易得多。"
      ]
    ],
    "evidence_cells": [
      "A11",
      "B11",
      "E11",
      "E1",
      "E2",
      "E3",
      "E4",
      "E5",
      "E6",
      "E7",
      "E8",
      "E9",
      "E12",
      "E10"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_e9fef14615_011",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "哪个模型在实体提取（NER、FINER-ORD）和情感分类（FPB、SC）任务上都表现出强大的泛化能力？",
    "answer": [
      [
        "GPT-4 在实体提取和情感分类数据集上都表现出色，与其他模型相比，其 EntityF1 和 F1 分数均获得高分。"
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "D2",
      "A3",
      "C3",
      "D3",
      "A5",
      "J5",
      "A9",
      "J9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]