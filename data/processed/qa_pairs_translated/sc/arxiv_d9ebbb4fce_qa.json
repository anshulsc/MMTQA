[
  {
    "question_id": "arxiv_d9ebbb4fce_001",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale modellu est isprigadu in modu espritzitu chi at otènnidu performàntzias State-of-the-Art (SOTA) in medas benchmarks?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_002",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Cantu de sos modellos listados incorporant sa tecnologia 'transformer' in s'innovatzione clave o in sa metodologia issoro?",
    "answer": [
      [
        "3"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_003",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Cales est s'innovatzione printzipale de su modellu chi impreat is strategies de treamentu multi-dataset?",
    "answer": [
      [
        "Open-source foundation model family"
      ]
    ],
    "evidence_cells": [
      "B2",
      "C2"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_004",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Cale modellu impreat una metodolugia chi trasformaiat datos temporales 1D in rappresentatzione 2D pro analizare sos patrones?",
    "answer": [
      [
        "TimesNet"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_005",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Enumera sos modellos chi sunt definidos comente 'foundation model' o chi impreant un abbigiu 'pre-trained' in s'innovatzione issoro.",
    "answer": [
      [
        "Timer"
      ],
      [
        "MOMENT"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A2",
      "B2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_006",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Cantos pro centu de sos modellos in custa lista impreant un architettura basade in sos transformers?",
    "answer": [
      [
        "60%"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5",
      "A1",
      "A2",
      "A3",
      "A4",
      "A5"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_007",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Si s' modelu de is referèntzias de unu documentu pro sa limba est unu testu de 5000 paràulas, cale modellu tenet su risultadu prus elevadu?",
    "answer": [
      [
        "Timer"
      ]
    ],
    "evidence_cells": [
      "A1",
      "D1"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_008",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "open_ended_reasoning",
    "question": "A pustis de sa tabedda, cale relatzione si podet inferrare in intro a sa metodolugia de un modellu e sos resultados primàrios, in particulare in cuncordu cun sas architeturas transformer?",
    "answer": [
      [
        "Sos datos suggerint una currelatzione in intro a s'adotzione de architeturas basadas in transformer e s'otènimentu de un performance forte in iscenàrios spesìficos e defferentes. Pro ezempru, su transformer pre-antradu-solu-decoder de Timer portat a un performance forte cun pagu datos (few-shot), mentras su transformer de PatchTST, indipendente dae su canali, resurtat in una ridutzione significativa de su MSE in sa previsura a longo termine. Custu implicat chi sas metodologias basadas in transformer sunt particularmente efetzivas pro sos tareas chi cunsistent in efetzientzia de datos (few-shot learning) o in sa capatzidade de otènnere dependèntzias de longu percursu (previsura a longo termine)."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "D1",
      "B5",
      "C5",
      "D5"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_009",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Cuae culonna contet informatziones chi descrient s'apògiu algorìtmicu o strutturale fundamentale de cada modellu?",
    "answer": [
      [
        "Methodology"
      ]
    ],
    "evidence_cells": [
      "C1",
      "C2",
      "C3",
      "C4",
      "C5"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_010",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale modellu est istétiu su resurtadu printzipale chi s'agatat prus a fora po àere otentu unu metre de performance specificu e quantitativu in logu de una descriptzione calitativa comente a performance 'forte' o 'superior'?",
    "answer": [
      [
        "PatchTST"
      ]
    ],
    "evidence_cells": [
      "A5",
      "D1",
      "D2",
      "D3",
      "D4",
      "D5"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_011",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Calu modello at otentu resurtados pius bonos in 18 dataset de benchmark?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  }
]