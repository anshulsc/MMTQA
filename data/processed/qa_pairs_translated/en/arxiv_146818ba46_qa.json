[
  {
    "question_id": "arxiv_146818ba46_001",
    "table_id": "arxiv_146818ba46",
    "question_type": "open_ended_reasoning",
    "question": "Which models offer Sublinear scalability, and what is the key difference in their supported features ('Pre-training', 'Multi-task')?",
    "answer": [
      [
        "TimeMixer and PatchTST offer Sublinear scalability. The key difference is that TimeMixer supports Multi-task learning while PatchTST does not; neither model uses Pre-training."
      ]
    ],
    "evidence_cells": [
      "A3",
      "B3",
      "C3",
      "E3",
      "A5",
      "B5",
      "C5",
      "E5"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_146818ba46_002",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "What is the total count of models that support either Pre-training or Multi-task learning, but not both?",
    "answer": [
      [
        "1"
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "B2",
      "C2",
      "B3",
      "C3",
      "B4",
      "C4",
      "B5",
      "C5"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_146818ba46_003",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "Identify the primary application of the model that has Linear scalability and Medium compute requirements.",
    "answer": [
      [
        "Task Flexibility"
      ]
    ],
    "evidence_cells": [
      "A4",
      "D4",
      "E4",
      "F4"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_146818ba46_004",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "If a research project evolves from requiring a model for 'Long Sequences' to later needing one with 'Task Flexibility', which model would be the appropriate choice at the second stage?",
    "answer": [
      [
        "TimesNet"
      ]
    ],
    "evidence_cells": [
      "A4",
      "F4",
      "F5"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_146818ba46_005",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "List the models that do not use pre-training and offer sublinear scalability.",
    "answer": [
      [
        "TimeMixer"
      ],
      [
        "PatchTST"
      ]
    ],
    "evidence_cells": [
      "A3",
      "B3",
      "E3",
      "A5",
      "B5",
      "E5"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_146818ba46_006",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "What proportion of the models listed require 'High' compute resources?",
    "answer": [
      [
        "40%"
      ]
    ],
    "evidence_cells": [
      "D1",
      "D2",
      "D3",
      "D4",
      "D5"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_146818ba46_007",
    "table_id": "arxiv_146818ba46",
    "question_type": "open_ended_reasoning",
    "question": "If 'TimesNet' were enhanced to support 'Pre-training', which existing model would it then most closely resemble in terms of its features (Pre-training, Multi-task, Compute, Scalability)?",
    "answer": [
      [
        "The enhanced TimesNet would not closely resemble any other single model. While it would share 'Pre-training', 'Multi-task', and 'Linear' scalability with Timer and MOMENT, its 'Medium' compute would still differentiate it from their 'High' compute requirements."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "D1",
      "E1",
      "B2",
      "C2",
      "D2",
      "E2",
      "B4",
      "C4",
      "D4",
      "E4"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_146818ba46_008",
    "table_id": "arxiv_146818ba46",
    "question_type": "open_ended_reasoning",
    "question": "Is there a discernible correlation between a model's scalability and its primary application's focus on sequence length or flexibility?",
    "answer": [
      [
        "Yes, there appears to be a correlation. Models with more efficient 'Sublinear' scalability (TimeMixer, PatchTST) are associated with applications involving complex patterns or long sequences ('Multiscale Patterns', 'Long Sequences'). In contrast, models with 'Linear' scalability tend to be applied to tasks requiring flexibility or learning under constraints ('Few-shot Learning', 'Limited Supervision', 'Task Flexibility')."
      ]
    ],
    "evidence_cells": [
      "E1",
      "F1",
      "E2",
      "F2",
      "E3",
      "F3",
      "E4",
      "F4",
      "E5",
      "F5"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_146818ba46_009",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "Which column, other than 'Model', contains the most diverse set of unique values?",
    "answer": [
      [
        "Primary Application"
      ]
    ],
    "evidence_cells": [
      "F1",
      "F2",
      "F3",
      "F4",
      "F5"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_146818ba46_010",
    "table_id": "arxiv_146818ba46",
    "question_type": "value",
    "question": "Which model is an outlier for not supporting either Pre-training or Multi-task learning?",
    "answer": [
      [
        "PatchTST"
      ]
    ],
    "evidence_cells": [
      "A5",
      "B1",
      "C1",
      "B2",
      "C2",
      "B3",
      "C3",
      "B4",
      "C4",
      "B5",
      "C5"
    ],
    "reasoning_category": "Outlier Detection"
  }
]