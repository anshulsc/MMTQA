[
  {
    "question_id": "arxiv_5e3be8dfe7_001",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "টেবিলে উল্লিখিত কোন মডেলটির সবচেয়ে বেশি স্বতন্ত্র প্যারামিটার ব্যাখ্যা রয়েছে?",
    "answer": [
      [
        "Neural Networks"
      ]
    ],
    "evidence_cells": [
      "A2",
      "A3",
      "A4",
      "A5",
      "A6",
      "A7",
      "A8",
      "A9",
      "A10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_002",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "যেসব মডেলের মূল সূত্রে সমষ্টি (Σ) ব্যবহার করা হয়েছে, সেগুলোর জন্য মোট কতগুলি পৃথক প্যারামিটার ব্যাখ্যা করা হয়েছে?",
    "answer": [
      [
        "8"
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "C5",
      "C6",
      "A9",
      "B9",
      "C9",
      "C10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_003",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "সেই মডেলগুলির তালিকা করুন যেগুলির প্রধান সূত্রে এক্সপোনেনসিয়েশন (যেমন, e^x) জড়িত নেই।",
    "answer": [
      [
        "Neural Networks"
      ],
      [
        "Support Vector Machine"
      ],
      [
        "Decision Tree"
      ]
    ],
    "evidence_cells": [
      "A2",
      "B2",
      "A4",
      "B4",
      "A7",
      "B7",
      "A9",
      "B9"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_004",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "তালিকাভুক্ত মডেলগুলির কত শতাংশ তাদের ফর্মুলেশনে পৃথক নমুনা বা ডেটা পয়েন্ট (যেমন, 'নমুনা i') প্রতিনিধিত্বকারী একটি প্যারামিটার ব্যবহার করে?",
    "answer": [
      [
        "50%"
      ]
    ],
    "evidence_cells": [
      "A2",
      "A4",
      "A7",
      "C8",
      "A9",
      "C9"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_005",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "একটি ডিসিশন ট্রি মডেলে নমুনার বিভাগগুলির সংখ্যা 'm' যদি 1 হয়, তবে সূত্র অনুসারে তথ্যের এনট্রপি 'Ent(D)' এর গণনাকৃত মান কত হবে?",
    "answer": [
      [
        "0"
      ]
    ],
    "evidence_cells": [
      "B9",
      "C10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_006",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "কোন মডেলের সূত্রটি অন্যগুলোর থেকে মৌলিকভাবে আলাদা কারণ এটিকে সরাসরি আউটপুট মানের গণনা না করে একটি অপ্টিমাইজেশান সমস্যা (মিনিমাইজেশান) হিসাবে উপস্থাপন করা হয়েছে?",
    "answer": [
      [
        "Support Vector Machine"
      ]
    ],
    "evidence_cells": [
      "B2",
      "B4",
      "B7",
      "B9"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_007",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "open_ended_reasoning",
    "question": "লজিস্টিক রিগ্রেশনে 'β' প্যারামিটারের ভূমিকা এবং সাপোর্ট ভেক্টর মেশিনে 'w' প্যারামিটারের ভূমিকার মধ্যে তুলনা করুন।",
    "answer": [
      [
        "লজিস্টিক রিগ্রেশনে, 'β' হলো রিগ্রেশন সহগের একটি সারি ভেক্টর যা, ইন্টারসেপ্টের সাথে, লজিস্টিক ফাংশনের মাধ্যমে একটি ফলাফলের সম্ভাবনা নির্ধারণ করে। সাপোর্ট ভেক্টর মেশিনে, 'w' হলো একটি প্যারামিটার ভেক্টর যা পৃথকীকরণ হাইপারপ্লেনের দিক নির্ধারণ করে। SVM-এ লক্ষ্য হলো 'w' খুঁজে বের করা যা ক্লাসগুলির মধ্যে মার্জিনকে সর্বাধিক করে এর L2 নর্ম কমিয়ে, যেখানে লজিস্টিক রিগ্রেশনে, 'β' সাধারণত পর্যবেক্ষণ করা ডেটার সম্ভাবনা বাড়িয়ে পাওয়া যায়।"
      ]
    ],
    "evidence_cells": [
      "B2",
      "C3",
      "B7",
      "C7"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_008",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "open_ended_reasoning",
    "question": "নিউরাল নেটওয়ার্কের 'লেয়ার' (l এবং l-1) এবং ডিসিশন ট্রি-এর 'এনট্রপি' (Ent(D)) ধারণাগুলি ডেটা থেকে শেখার ক্ষেত্রে তাদের ভিন্ন পদ্ধতিগুলিকে কীভাবে প্রতিফলিত করে?",
    "answer": [
      [
        "নিউরাল নেটওয়ার্কের 'লেয়ার' (l এবং l-1) ধারণাটি একটি পর্যায়ক্রমিক বৈশিষ্ট্য শেখার পদ্ধতিকে প্রতিফলিত করে। মডেলটি পর পর লেয়ারগুলিতে অ্যাক্টিভেশনগুলি পাস করে ডেটার ক্রমবর্ধমান জটিল উপস্থাপনা শেখে, একটি জটিল ফাংশন অ্যাপ্রক্সিমেটর তৈরি করতে ওজন ('w') এবং বায়াস ('b') সামঞ্জস্য করে। বিপরীতে, ডিসিশন ট্রি-এর 'এনট্রপি' (Ent(D)) ধারণাটি একটি লোভী, নিয়ম-ভিত্তিক পদ্ধতির প্রতিফলন করে। মডেলটি এনট্রপি (তথ্যের লাভ) হ্রাসকে সবচেয়ে বেশি প্রভাবিত করে এমন বৈশিষ্ট্যগুলি নির্বাচন করে ডেটাটিকে পুনরাবৃত্তিমূলকভাবে শুদ্ধ সাবসেটে বিভক্ত করে, যা if-then নিয়মগুলির একটি সুস্পষ্ট সেট তৈরি করে।"
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "C5",
      "C6",
      "A9",
      "B9",
      "C9"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_009",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "টেবিলে বর্ণিত স্বতন্ত্র মডেলগুলির মোট সংখ্যা কত?",
    "answer": [
      [
        "4"
      ]
    ],
    "evidence_cells": [
      "A2",
      "A4",
      "A7",
      "A9"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_5e3be8dfe7_010",
    "table_id": "arxiv_5e3be8dfe7",
    "question_type": "value",
    "question": "কোন কলামের প্রধান উদ্দেশ্য হলো সংলগ্ন কলামে ব্যবহৃত ভেরিয়েবলগুলো সংজ্ঞায়িত করা?",
    "answer": [
      [
        "Parameter and Explanation"
      ]
    ],
    "evidence_cells": [
      "B0",
      "C0",
      "B2",
      "C2",
      "B4",
      "C4"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  }
]