[
  {
    "question_id": "arxiv_e9fef14615_001",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'ccfraud' डेटासेट पर किस मॉडल ने उच्चतम F1 स्कोर प्राप्त किया?",
    "answer": [
      [
        "Gemini"
      ]
    ],
    "evidence_cells": [
      "A4",
      "E4",
      "C4",
      "D4",
      "F4",
      "G4",
      "H4",
      "I4",
      "J4",
      "K4",
      "L4",
      "M4",
      "N4",
      "O4",
      "E10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_002",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'GPT 4' मॉडल के लिए सभी डेटासेट में 'Acc' (सटीकता) स्कोर का औसत क्या है जहाँ इस मीट्रिक का उपयोग किया गया था?",
    "answer": [
      [
        "0.543"
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B5",
      "D5",
      "B9",
      "D9",
      "D10"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_e9fef14615_003",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "उस डेटासेट की पहचान करें जहाँ 'FinMA 7B' ने अपना उच्चतम स्कोर प्राप्त किया, और फिर उन मॉडल (मॉडल) की सूची बनाएं जिन्होंने उसी कार्य पर शून्य स्कोर किया।",
    "answer": [
      [
        "taiwan",
        "Falcon 7B"
      ]
    ],
    "evidence_cells": [
      "A11",
      "I11",
      "L11",
      "I1",
      "I2",
      "I3",
      "I4",
      "I5",
      "I6",
      "I7",
      "I8",
      "I9",
      "I12",
      "I10",
      "L10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_004",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'TSA' डेटासेट पर, कौन सा मॉडल अपने बाईं ओर के कॉलम में सूचीबद्ध मॉडल की तुलना में सबसे बड़ी प्रदर्शन गिरावट दिखाता है, और इस गिरावट का मान क्या है?",
    "answer": [
      [
        "FinGPT 7B-lora",
        "0.80"
      ]
    ],
    "evidence_cells": [
      "A3",
      "I3",
      "J3",
      "I10",
      "J10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_005",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "उन सभी डेटासेट की पहचान करें जहाँ 'Gemini' मॉडल ने 0.90 या उससे अधिक का स्कोर प्राप्त किया, और 'Chat GPT' मॉडल का स्कोर 0.20 या उससे कम रहा।",
    "answer": [
      [
        "ccfraud"
      ],
      [
        "taiwan"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4",
      "E4",
      "A11",
      "C11",
      "E11",
      "C10",
      "E10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_006",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'LendingClub' डेटासेट के लिए, इस कार्य के लिए तीन शीर्ष-प्रदर्शन करने वाले मॉडलों के संचयी स्कोर का कितना प्रतिशत योगदान है? एक दशमलव स्थान तक पूर्णांकित करें।",
    "answer": [
      [
        "41.3%"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C6",
      "D6",
      "E6",
      "F6",
      "G6",
      "H6",
      "I6",
      "J6",
      "K6",
      "L6",
      "M6",
      "N6",
      "O6"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_e9fef14615_007",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'LLaMA2 70B' मॉडल के लिए यदि हर स्कोर में 10% की वृद्धि की जाती है, तो सभी मूल्यांकित कार्यों में उसका नया औसत स्कोर क्या होगा? तीन दशमलव स्थानों तक पूर्णांकित करें।",
    "answer": [
      [
        "0.354"
      ]
    ],
    "evidence_cells": [
      "G1",
      "G2",
      "G3",
      "G4",
      "G5",
      "G6",
      "G7",
      "G8",
      "G9",
      "G11",
      "G12",
      "G10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_008",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "'F1' या 'MicroF1' मेट्रिक्स द्वारा मापे गए कार्यों की जाँच करें। क्या 'GPT 4' और 'Gemini' मॉडलों के बीच प्रदर्शन का कोई सुसंगत संबंध है? अपने तर्क की व्याख्या करें।",
    "answer": [
      [
        "कोई मजबूत सकारात्मक सहसंबंध नहीं है, लेकिन एक स्पष्ट प्रदर्शन पदानुक्रम है। F1-आधारित कार्यों पर, Gemini लगातार GPT 4 से बेहतर प्रदर्शन करता है या उसके बराबर है। 'ccfraud' और 'taiwan' डेटासेट के लिए, Gemini के स्कोर (क्रमशः 0.90 और 0.95) GPT 4 के स्कोर (दोनों के लिए 0.55) से काफी अधिक हैं। 'LendingClub' के लिए, Gemini (0.65) अभी भी GPT 4 (0.55) से थोड़ा अधिक है। केवल 'MLESG' डेटासेट पर उनके स्कोर लगभग समान हैं (0.35 बनाम 0.34)। यह बताता है कि जबकि उनका प्रदर्शन कसकर सहसंबद्ध नहीं है, Gemini आम तौर पर इन विशिष्ट F1-मापे गए कार्यों के लिए एक बेहतर मॉडल है।"
      ]
    ],
    "evidence_cells": [
      "B4",
      "D4",
      "E4",
      "B6",
      "D6",
      "E6",
      "B11",
      "D11",
      "E11",
      "B12",
      "D12",
      "E12",
      "D10",
      "E10"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_e9fef14615_009",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "प्रदर्शन डेटा के आधार पर, कौन से दो डेटासेट हर एक परीक्षण मॉडल में शून्य स्कोर दिखाते हैं, जो एक संभावित मूल्यांकन विफलता का सुझाव देते हैं या ऐसा कार्य जिसे कोई भी मॉडल पूरा नहीं कर सका?",
    "answer": [
      [
        "FNXL"
      ],
      [
        "ECTSUM"
      ]
    ],
    "evidence_cells": [
      "A7",
      "C7",
      "D7",
      "E7",
      "F7",
      "G7",
      "H7",
      "I7",
      "J7",
      "K7",
      "L7",
      "M7",
      "N7",
      "O7",
      "A8",
      "C8",
      "D8",
      "E8",
      "F8",
      "G8",
      "H8",
      "I8",
      "J8",
      "K8",
      "L8",
      "M8",
      "N8",
      "O8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_010",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "'Gemini' मॉडल के लिए, कौन सा डेटासेट स्कोर सबसे महत्वपूर्ण सकारात्मक प्रदर्शन आउटलायर दर्शाता है, और क्यों?",
    "answer": [
      [
        "टाईवान डेटासेट (0.95) का स्कोर जेमिनी मॉडल के लिए सबसे महत्वपूर्ण सकारात्मक आउटलायर है। जेमिनी के गैर-शून्य स्कोर का औसत लगभग 0.615 आता है। 0.95 का स्कोर उच्चतम मान है और अन्य सभी स्कोरों की तुलना में इस औसत से सबसे दूर है। यह असामान्य रूप से उच्च प्रदर्शन बताता है कि जेमिनी मॉडल 'टाईवान' डेटासेट और 'F1' मीट्रिक द्वारा परिभाषित कार्य के लिए असाधारण रूप से उपयुक्त है, या यह कार्य ही इस मॉडल के लिए दूसरों की तुलना में काफी आसान था।"
      ]
    ],
    "evidence_cells": [
      "A11",
      "B11",
      "E11",
      "E1",
      "E2",
      "E3",
      "E4",
      "E5",
      "E6",
      "E7",
      "E8",
      "E9",
      "E12",
      "E10"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_e9fef14615_011",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "कौन सा मॉडल एंटिटी एक्सट्रैक्शन (NER, FINER-ORD) और सेंटीमेंट क्लासिफिकेशन (FPB, SC) दोनों कार्यों में मजबूत सामान्यीकरण प्रदर्शित करता है?",
    "answer": [
      [
        "GPT-4 लगातार दोनों एंटिटी एक्सट्रैक्शन और सेंटीमेंट क्लासिफिकेशन डेटासेट में अच्छा प्रदर्शन करता है, अन्य मॉडलों की तुलना में उच्च EntityF1 और F1 स्कोर प्राप्त करता है।"
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "D2",
      "A3",
      "C3",
      "D3",
      "A5",
      "J5",
      "A9",
      "J9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]