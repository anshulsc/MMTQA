[
  {
    "question_id": "arxiv_d9ebbb4fce_001",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale modello è esplicitamente menzionato per aver raggiunto prestazioni all'avanguardia (SOTA) su numerosi benchmark?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_002",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quanti dei modelli elencati incorporano la tecnologia 'transformer' nella loro innovazione chiave o metodologia?",
    "answer": [
      [
        "3"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_003",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Qual è l'innovazione chiave del modello che utilizza strategie di addestramento multi-dataset?",
    "answer": [
      [
        "Open-source foundation model family"
      ]
    ],
    "evidence_cells": [
      "B2",
      "C2"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_004",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale modello trasforma i dati temporali 1D in una rappresentazione 2D per analizzare i pattern?",
    "answer": [
      [
        "TimesNet"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_005",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Elenca i modelli che sono descritti come 'foundation model' o utilizzano un approccio 'pre-trained' nella loro innovazione.",
    "answer": [
      [
        "Timer"
      ],
      [
        "MOMENT"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A2",
      "B2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_006",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale percentuale dei modelli in questo elenco utilizza un'architettura basata su transformer?",
    "answer": [
      [
        "60%"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5",
      "A1",
      "A2",
      "A3",
      "A4",
      "A5"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_007",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Se il vincolo principale di un team di ricerca è una quantità molto piccola di dati di addestramento (1-5%), quali risultati del modello suggeriscono che sarebbe la scelta più efficace?",
    "answer": [
      [
        "Timer"
      ]
    ],
    "evidence_cells": [
      "A1",
      "D1"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_008",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "open_ended_reasoning",
    "question": "Basandosi sulla tabella, quale relazione si può inferire tra la metodologia di un modello e i suoi risultati principali, in particolare per quanto riguarda le architetture transformer?",
    "answer": [
      [
        "I dati suggeriscono una correlazione tra l'adozione di architetture basate su transformer e il raggiungimento di prestazioni elevate in scenari specifici e impegnativi. Ad esempio, il transformer pre-addestrato solo decoder di Timer porta a prestazioni forti in pochi esempi (few-shot performance), mentre il transformer indipendente dal canale di PatchTST si traduce in una significativa riduzione dell'MSE nella previsione a lungo termine. Ciò implica che le metodologie basate su transformer sono particolarmente efficaci per compiti che richiedono sia efficienza dei dati (apprendimento few-shot) sia la cattura di dipendenze a lungo raggio (previsione a lungo termine)."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "D1",
      "B5",
      "C5",
      "D5"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_009",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale colonna contiene informazioni che descrivono l'approccio algoritmico o strutturale fondamentale di ciascun modello?",
    "answer": [
      [
        "Methodology"
      ]
    ],
    "evidence_cells": [
      "C1",
      "C2",
      "C3",
      "C4",
      "C5"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_010",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale modello presenta un risultato primario che si distingue fornendo una metrica di performance specifica e quantitativa invece di una descrizione qualitativa come performance 'forte' o 'superiore'?",
    "answer": [
      [
        "PatchTST"
      ]
    ],
    "evidence_cells": [
      "A5",
      "D1",
      "D2",
      "D3",
      "D4",
      "D5"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_011",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Quale modello ha superato tutti gli altri in 18 set di dati di benchmark?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  }
]