[
  {
    "question_id": "arxiv_e9fef14615_001",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'ccfraud' データセットにおいて、最も高いF1スコアを達成したモデルはどれですか？",
    "answer": [
      [
        "Gemini"
      ]
    ],
    "evidence_cells": [
      "A4",
      "E4",
      "C4",
      "D4",
      "F4",
      "G4",
      "H4",
      "I4",
      "J4",
      "K4",
      "L4",
      "M4",
      "N4",
      "O4",
      "E10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_002",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'GPT 4'モデルで、このメトリクスが使用されたすべてのデータセットにおける平均精度（'Acc'）スコアは何ですか？",
    "answer": [
      [
        "0.543"
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B5",
      "D5",
      "B9",
      "D9",
      "D10"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_e9fef14615_003",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'FinMA 7B'が最高スコアを達成したデータセットを特定し、その同じタスクでゼロスコアを記録したモデルをリストアップしてください。",
    "answer": [
      [
        "taiwan",
        "Falcon 7B"
      ]
    ],
    "evidence_cells": [
      "A11",
      "I11",
      "L11",
      "I1",
      "I2",
      "I3",
      "I4",
      "I5",
      "I6",
      "I7",
      "I8",
      "I9",
      "I12",
      "I10",
      "L10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_004",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'TSA'データセットにおいて、左隣の列のモデルと比較して最もパフォーマンスが低下したモデルはどれで、その低下値はいくらですか？",
    "answer": [
      [
        "FinGPT 7B-lora",
        "0.80"
      ]
    ],
    "evidence_cells": [
      "A3",
      "I3",
      "J3",
      "I10",
      "J10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_005",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'Gemini'モデルが0.90以上のスコアを達成し、かつ'Chat GPT'モデルが0.20以下のスコアであったデータセットをすべて特定してください。",
    "answer": [
      [
        "ccfraud"
      ],
      [
        "taiwan"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4",
      "E4",
      "A11",
      "C11",
      "E11",
      "C10",
      "E10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_006",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'LendingClub'データセットにおいて、このタスクにおける上位3つのモデルが達成した累積スコアの割合は何パーセントですか？小数点以下第一位を四捨五入してください。",
    "answer": [
      [
        "41.3%"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C6",
      "D6",
      "E6",
      "F6",
      "G6",
      "H6",
      "I6",
      "J6",
      "K6",
      "L6",
      "M6",
      "N6",
      "O6"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_e9fef14615_007",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "「LLaMA2 70B」モデルの全評価タスクにおけるスコアがそれぞれ10%向上した場合、その新しい平均スコアはいくつになりますか？小数点以下3桁まで丸めてください。",
    "answer": [
      [
        "0.354"
      ]
    ],
    "evidence_cells": [
      "G1",
      "G2",
      "G3",
      "G4",
      "G5",
      "G6",
      "G7",
      "G8",
      "G9",
      "G11",
      "G12",
      "G10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_008",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "'F1'または'MicroF1'メトリクスで測定されたタスクを検討してください。'GPT 4'と'Gemini'モデルの間に一貫したパフォーマンス関係はありますか？その理由を説明してください。",
    "answer": [
      [
        "強い正の相関関係はありませんが、明確なパフォーマンスの階層があります。F1ベースのタスクでは、GeminiはGPT 4を一貫して上回るか、同等です。'ccfraud'および'taiwan'データセットでは、Geminiのスコア（それぞれ0.90および0.95）はGPT 4のスコア（両方とも0.55）よりも大幅に高くなっています。'LendingClub'では、Gemini（0.65）はGPT 4（0.55）よりも依然として中程度高くなっています。'MLESG'データセットでのみ、スコアはほぼ同一です（0.35対0.34）。これは、パフォーマンスが厳密に相関しているわけではないものの、Geminiがこれらの特定のF1測定タスクにおいて一般的に優れたモデルであることを示唆しています。"
      ]
    ],
    "evidence_cells": [
      "B4",
      "D4",
      "E4",
      "B6",
      "D6",
      "E6",
      "B11",
      "D11",
      "E11",
      "B12",
      "D12",
      "E12",
      "D10",
      "E10"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_e9fef14615_009",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "パフォーマンスデータに基づくと、テストされたすべてのモデルでスコアがゼロになっているデータセットはどれですか。これは、評価の失敗またはどのモデルも完了できなかったタスクを示唆しています。",
    "answer": [
      [
        "FNXL"
      ],
      [
        "ECTSUM"
      ]
    ],
    "evidence_cells": [
      "A7",
      "C7",
      "D7",
      "E7",
      "F7",
      "G7",
      "H7",
      "I7",
      "J7",
      "K7",
      "L7",
      "M7",
      "N7",
      "O7",
      "A8",
      "C8",
      "D8",
      "E8",
      "F8",
      "G8",
      "H8",
      "I8",
      "J8",
      "K8",
      "L8",
      "M8",
      "N8",
      "O8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_010",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "'Gemini'モデルにおいて、最も顕著なポジティブな外れ値を示すデータセットのスコアは何であり、その理由はなぜですか？",
    "answer": [
      [
        "「taiwan」データセットのスコア（0.95）が、Geminiモデルにとって最も顕著なポジティブな外れ値です。Geminiのゼロ以外のスコアの平均を計算すると、約0.615になります。0.95というスコアは、他のすべてのスコアと比較して、この平均から最も離れた最高の値です。この異常に高いパフォーマンスは、Geminiモデルが「taiwan」データセットと「F1」メトリックで定義されたタスクに異常に適合しているか、あるいはそのタスク自体が他のモデルよりもこのモデルにとって大幅に容易であったことを示唆しています。"
      ]
    ],
    "evidence_cells": [
      "A11",
      "B11",
      "E11",
      "E1",
      "E2",
      "E3",
      "E4",
      "E5",
      "E6",
      "E7",
      "E8",
      "E9",
      "E12",
      "E10"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_e9fef14615_011",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "エンティティ抽出（NER、FINER-ORD）およびセンチメント分類（FPB、SC）の両方のタスクにわたって堅牢な汎化を示すモデルはどれですか？",
    "answer": [
      [
        "GPT-4は、エンティティ抽出とセンチメント分類の両方のデータセットで一貫して良好なパフォーマンスを発揮し、他のモデルと比較して高いEntityF1スコアとF1スコアを達成しています。"
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "D2",
      "A3",
      "C3",
      "D3",
      "A5",
      "J5",
      "A9",
      "J9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]