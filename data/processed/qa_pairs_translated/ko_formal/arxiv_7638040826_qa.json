[
  {
    "question_id": "arxiv_7638040826_001",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "중앙 은행이 통화 정책의 영향을 이해하기 위해 사용하는 언어에 특별히 초점을 맞춘 데이터셋은 무엇이며, 누가 발표했습니까?",
    "answer": [
      [
        "Trillion Dollar Words",
        "Shah et al. (2023a)"
      ]
    ],
    "evidence_cells": [
      "A5",
      "B5",
      "C5"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_002",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "2020년 이후에 게시되었으며, 인력이 직접 주석을 달았거나 전문가가 작성했다고 명시적으로 설명된 모든 자료들을 나열해 주십시오.",
    "answer": [
      [
        "SEntFiN 1.0"
      ],
      [
        "Gold Commodity Dataset"
      ],
      [
        "FINQA"
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "A7",
      "B7",
      "C7",
      "A10",
      "B10",
      "C10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_003",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "게시 연도를 기준으로 2010년대 초반부터 2020년대까지 이러한 금융 데이터셋의 초점 변화를 설명해 주십시오.",
    "answer": [
      [
        "데이터셋은 2010년대 초반의 기본적인 감성 분석에서 2020년대의 더 복잡하고 전문적인 작업으로 초점이 진화했음을 보여줍니다. SentiWordNet(2010) 및 Financial Phrase Bank(2014)와 같은 초기 리소스는 일반적인 단어/구문의 감성을 다루었습니다. 반대로, SEntFiN 1.0(개체별 감성), REFinD(관계 추출), FINQA(심층 추론)와 같은 2020년대의 리소스는 더 세분화되고 복잡한 NLP 문제를 다루며, 금융 텍스트에 대한 더 미묘한 이해를 향한 분야의 성숙을 나타냅니다."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "B2",
      "C2",
      "B4",
      "C4",
      "B6",
      "C6",
      "B10",
      "C10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_004",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "나열된 자료 중 주로 감성 분석(긍정, 부정 또는 중립 레이블 지정)에 초점을 맞춘 자료는 몇 개입니까?",
    "answer": [
      [
        "4"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A2",
      "B2",
      "A3",
      "B3",
      "A4",
      "B4"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_7638040826_005",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "다른 리소스에 비해 지리적 초점이 특이한 리소스는 무엇입니까?",
    "answer": [
      [
        "Financial Phrase Bank"
      ]
    ],
    "evidence_cells": [
      "A2",
      "B2"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_7638040826_006",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "나열된 데이터셋 중 몇 퍼센트가 2023년에 출판되었습니까?",
    "answer": [
      [
        "40%"
      ]
    ],
    "evidence_cells": [
      "C5",
      "C6",
      "C8",
      "C9"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_7638040826_007",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "'SEntFiN 1.0' 데이터셋이 제외된다면, 뉴스 헤드라인 분석에 초점을 맞춘 가장 최근에 출판된 자료는 무엇인가요?",
    "answer": [
      [
        "MULTIFIN"
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "A7",
      "B7",
      "C7",
      "A9",
      "B9",
      "C9"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_008",
    "table_id": "arxiv_7638040826",
    "question_type": "value",
    "question": "이 목록에서 가장 많은 수의 개별 리소스에 기여한 저자 또는 저자 그룹은 누구입니까?",
    "answer": [
      [
        "Shah et al."
      ]
    ],
    "evidence_cells": [
      "C5",
      "C8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_009",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "'FiNER'와 'REFinD'가 다루는 주요 NLP 작업를 비교 설명해 주십시오.",
    "answer": [
      [
        "'FiNER'는 개체명 인식(NER)이라는 기본적인 NLP 작업을 위해 설계되었으며, 이는 금융 회사와 같은 개체를 식별하고 분류하는 것을 포함합니다. 'REFinD'는 이미 식별된 개체 간의 관계(예: 사람-직책, 조직-금액)를 식별하는 것을 목표로 하는, 보다 복잡하고 후속적인 작업인 관계 추출을 다룹니다. 따라서 FiNER는 '행위자'를 식별하는 데 중점을 두는 반면, REFinD는 '상호작용'을 식별하는 데 중점을 둡니다."
      ]
    ],
    "evidence_cells": [
      "B6",
      "B8"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_7638040826_010",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "설명에 따르면, '헤드라인'에 초점을 맞춘 데이터셋과 해당 발행 연도의 최신성 사이에 상관관계가 있습니까? 그 이유를 설명하십시오.",
    "answer": [
      [
        "네, 양의 상관관계가 있는 것으로 보입니다. 설명에 '헤드라인'이 명시적으로 언급된 세 가지 데이터셋(SEntFiN 1.0, Gold Commodity Dataset, MULTIFIN)은 모두 2021년 또는 그 이후에 발행되었습니다. 2010년대에 발행된 이전 데이터셋에서는 이러한 특정 초점을 언급하지 않습니다. 이는 최근 몇 년간 금융 뉴스 헤드라인의 간결하고 영향력 있는 언어를 분석하는 데 대한 연구 관심이 증가하고 있음을 시사합니다."
      ]
    ],
    "evidence_cells": [
      "B4",
      "C4",
      "B7",
      "C7",
      "B9",
      "C9"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_7638040826_011",
    "table_id": "arxiv_7638040826",
    "question_type": "open_ended_reasoning",
    "question": "금융 텍스트 분석에서 SenticNet과 비교했을 때 SentiWordNet의 주요 목적은 무엇인가요?",
    "answer": [
      [
        "SentiWordNet은 개별 단어 감각에 감정 점수(긍정, 부정, 객관)를 할당하여 정량화하는 반면, SenticNet은 인공지능과 시맨틱 웹 기술을 결합하여 금융 맥락 내에서 의견을 해석하고 처리합니다."
      ]
    ],
    "evidence_cells": [
      "A1",
      "A3",
      "B1",
      "B3"
    ],
    "reasoning_category": "Comparative Reasoning"
  }
]