[
  {
    "question_id": "arxiv_e9fef14615_001",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'ccfraud' dataset-ində hansı model ən yüksək F1 balını əldə edib?",
    "answer": [
      [
        "Gemini"
      ]
    ],
    "evidence_cells": [
      "A4",
      "E4",
      "C4",
      "D4",
      "F4",
      "G4",
      "H4",
      "I4",
      "J4",
      "K4",
      "L4",
      "M4",
      "N4",
      "O4",
      "E10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_002",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'GPT 4' modelinin bu metrik istifadə olunan bütün məlumat dəstləri üzrə orta dəqiqlik ('Acc') balı nə qədərdir?",
    "answer": [
      [
        "0.543"
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B5",
      "D5",
      "B9",
      "D9",
      "D10"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_e9fef14615_003",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'FinMA 7B' modelinin ən yüksək nəticə göstərdiyi verilənlər dəstini müəyyən edin və sonra həmin tapşırıqda sıfır bal toplamış model(lər)i siyahıya alın.",
    "answer": [
      [
        "taiwan",
        "Falcon 7B"
      ]
    ],
    "evidence_cells": [
      "A11",
      "I11",
      "L11",
      "I1",
      "I2",
      "I3",
      "I4",
      "I5",
      "I6",
      "I7",
      "I8",
      "I9",
      "I12",
      "I10",
      "L10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_004",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'TSA' datasettində hansı model özündən əvvəlki sütunda göstərilən modelə nisbətən ən böyük performans düşüşünü nümayiş etdirir və bu düşüşün dəyəri nədir?",
    "answer": [
      [
        "FinGPT 7B-lora",
        "0.80"
      ]
    ],
    "evidence_cells": [
      "A3",
      "I3",
      "J3",
      "I10",
      "J10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_005",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'Gemini' modelinin 0.90 və ya daha yüksək, 'Chat GPT' modelinin isə 0.20 və ya daha az bal topladığı bütün verilən dəstlərini müəyyən edin.",
    "answer": [
      [
        "ccfraud"
      ],
      [
        "taiwan"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4",
      "E4",
      "A11",
      "C11",
      "E11",
      "C10",
      "E10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_006",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'LendingClub' datasettində bu tapşırıq üçün ən yaxşı nəticə göstərən üç modelin ümumi balının neçə faizi xərclənir? Bir onluq yerə qədər yuvarlaqlaşdırın.",
    "answer": [
      [
        "41.3%"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C6",
      "D6",
      "E6",
      "F6",
      "G6",
      "H6",
      "I6",
      "J6",
      "K6",
      "L6",
      "M6",
      "N6",
      "O6"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_e9fef14615_007",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "'LLaMA2 70B' modelinin hər bir balı 10% artırılarsa, qiymətləndirilən bütün tapşırıqlar üzrə yeni orta balı nə olardı? Üç onluq yerə qədər yuvarlaqlaşdırın.",
    "answer": [
      [
        "0.354"
      ]
    ],
    "evidence_cells": [
      "G1",
      "G2",
      "G3",
      "G4",
      "G5",
      "G6",
      "G7",
      "G8",
      "G9",
      "G11",
      "G12",
      "G10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_008",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "'F1' və ya 'MicroF1' metrikiləri ilə ölçülən tapşırıqları araşdırın. 'GPT 4' və 'Gemini' modelləri arasında ardıcıl bir performans əlaqəsi varmı? Niyə belə düşünürsünüz?",
    "answer": [
      [
        "Güclü müsbət əlaqə yoxdur, lakin aydın bir performans iyerarxiyası var. F1 əsaslı tapşırıqlarda Gemini, GPT 4-dən üstündür və ya ona bərabərdir. 'ccfraud' və 'taiwan' məlumat dəstləri üçün Gemini'nin nəticələri (0.90 və 0.95) GPT 4-dən (hər ikisi üçün 0.55) əhəmiyyətli dərəcədə yüksəkdir. 'LendingClub' üçün Gemini (0.65), GPT 4-dən (0.55) hələ də orta dərəcədə yüksəkdir. Yalnız 'MLESG' məlumat dəstində nəticələri demək olar ki, eynidir (0.35-ə qarşı 0.34). Bu, onların performansının sıx əlaqəli olmamasına baxmayaraq, Gemini'nin ümumilikdə bu F1 ilə ölçülən tapşırıqlar üçün daha üstün bir model olduğunu göstərir."
      ]
    ],
    "evidence_cells": [
      "B4",
      "D4",
      "E4",
      "B6",
      "D6",
      "E6",
      "B11",
      "D11",
      "E11",
      "B12",
      "D12",
      "E12",
      "D10",
      "E10"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_e9fef14615_009",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Performans məlumatlarına əsasən, hər bir sınaqdan keçirilmiş model üzrə sıfır bal toplayan, potensial qiymətləndirmənin uğursuzluğunu və ya heç bir modelin tamamlaya bilmədiyi bir vəzifəni göstərən hansı iki məlumat dəsti idi?",
    "answer": [
      [
        "FNXL"
      ],
      [
        "ECTSUM"
      ]
    ],
    "evidence_cells": [
      "A7",
      "C7",
      "D7",
      "E7",
      "F7",
      "G7",
      "H7",
      "I7",
      "J7",
      "K7",
      "L7",
      "M7",
      "N7",
      "O7",
      "A8",
      "C8",
      "D8",
      "E8",
      "F8",
      "G8",
      "H8",
      "I8",
      "J8",
      "K8",
      "L8",
      "M8",
      "N8",
      "O8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_010",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "'Gemini' modeli üçün hansı məlumat dəstinin balı ən əhəmiyyətli müsbət kənarlaşmanı təmsil edir və niyə?",
    "answer": [
      [
        " 'Tayvan' məlumat dəsti üçün olan hesab (0.95) Gemini modeli üçün ən əhəmiyyətli müsbət kənarlaşmadır. Gemini-nin sıfır olmayan hesablarının ortalamasını hesablamaq təxminən 0.615 verir. 0.95 balı ən yüksək dəyərdir və digər bütün bal ilə müqayisədə bu ortalamadan ən uzaqdır. Bu qeyri-adi yüksək performans, Gemini modelinin 'tayvan' məlumat dəsti və 'F1' metrikası ilə müəyyən edilmiş tapşırıq üçün istisnai dərəcədə uyğun olduğunu və ya tapşırığın özünün bu model üçün digərlərindən əhəmiyyətli dərəcədə daha asan olduğunu göstərir."
      ]
    ],
    "evidence_cells": [
      "A11",
      "B11",
      "E11",
      "E1",
      "E2",
      "E3",
      "E4",
      "E5",
      "E6",
      "E7",
      "E8",
      "E9",
      "E12",
      "E10"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_e9fef14615_011",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Hans model qurğu çıxarılması (NER, FINER-ORD) və həssaslıq təsnifatı (FPB, SC) tapşırıqları üzrə etibarlı ümumiləşdirmə nümayiş etdirir?",
    "answer": [
      [
        "GPT-4, digər modellərlə müqayisədə yüksək EntityF1 və F1 balı toplayaraq, həm qurğu çıxarılması, həm də həssaslıq təsnifatı məlumat dəstləri üzrə ardıcıl olaraq yaxşı performans göstərir."
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "D2",
      "A3",
      "C3",
      "D3",
      "A5",
      "J5",
      "A9",
      "J9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]