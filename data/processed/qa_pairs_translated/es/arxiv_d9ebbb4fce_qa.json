[
  {
    "question_id": "arxiv_d9ebbb4fce_001",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Qué modelo se menciona explícitamente que ha logrado un rendimiento de vanguardia (SOTA) en numerosos benchmarks?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_002",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Cuántos de los modelos listados incorporan la tecnología 'transformer' en su innovación clave o metodología?",
    "answer": [
      [
        "3"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_003",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Cuál es la innovación clave del modelo que utiliza estrategias de entrenamiento con múltiples conjuntos de datos?",
    "answer": [
      [
        "Open-source foundation model family"
      ]
    ],
    "evidence_cells": [
      "B2",
      "C2"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_004",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿La metodología de qué modelo implica transformar datos temporales 1D en una representación 2D para analizar patrones?",
    "answer": [
      [
        "TimesNet"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_005",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "Enumera los modelos que se describen como 'modelo fundacional' o que utilizan un enfoque 'pre-entrenado' en su innovación.",
    "answer": [
      [
        "Timer"
      ],
      [
        "MOMENT"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A2",
      "B2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_006",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Qué porcentaje de los modelos en esta lista utilizan una arquitectura basada en transformadores?",
    "answer": [
      [
        "60%"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B5",
      "C5",
      "A1",
      "A2",
      "A3",
      "A4",
      "A5"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_007",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Si la principal limitación de un equipo de investigación es una cantidad muy pequeña de datos de entrenamiento (1-5%), los resultados de qué modelo sugieren que sería la opción más efectiva?",
    "answer": [
      [
        "Timer"
      ]
    ],
    "evidence_cells": [
      "A1",
      "D1"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_008",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "open_ended_reasoning",
    "question": "Según la tabla, ¿qué relación se puede inferir entre la metodología de un modelo y sus resultados primarios, particularmente en lo que respecta a las arquitecturas Transformer?",
    "answer": [
      [
        "Los datos sugieren una correlación entre la adopción de arquitecturas basadas en Transformer y la consecución de un rendimiento sólido en escenarios específicos y desafiantes. Por ejemplo, el Transformer pre-entrenado de solo decodificador de Timer conduce a un fuerte rendimiento con pocos ejemplos (few-shot), mientras que el Transformer independiente de canales de PatchTST resulta en una reducción significativa del MSE en la predicción a largo plazo. Esto implica que las metodologías basadas en Transformer son particularmente efectivas para tareas que requieren eficiencia de datos (aprendizaje con pocos ejemplos) o la captura de dependencias a largo plazo (predicción a largo plazo)."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "D1",
      "B5",
      "C5",
      "D5"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_009",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Qué columna contiene información que describe el enfoque algorítmico o estructural fundamental de cada modelo?",
    "answer": [
      [
        "Methodology"
      ]
    ],
    "evidence_cells": [
      "C1",
      "C2",
      "C3",
      "C4",
      "C5"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_010",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Cuál es el resultado principal de un modelo que se destaca por proporcionar una métrica de rendimiento específica y cuantitativa en lugar de una descripción cualitativa como 'rendimiento fuerte' o 'superior'?",
    "answer": [
      [
        "PatchTST"
      ]
    ],
    "evidence_cells": [
      "A5",
      "D1",
      "D2",
      "D3",
      "D4",
      "D5"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_d9ebbb4fce_011",
    "table_id": "arxiv_d9ebbb4fce",
    "question_type": "value",
    "question": "¿Qué modelo superó a todos los modelos en 18 conjuntos de datos de referencia?",
    "answer": [
      [
        "TimeMixer"
      ]
    ],
    "evidence_cells": [
      "A3",
      "D3"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  }
]