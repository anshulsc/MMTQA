[
  {
    "question_id": "arxiv_63416afda1_001",
    "table_id": "arxiv_63416afda1",
    "question_type": "value",
    "question": "Tī sú-sè hō͘-chúⁿ sî-chūn-ê oān-á chu-liāu bô͘-hêng, i ū chóaⁿ-iūⁿ ê tōe-oân ê lūi-hêng?",
    "answer": [
      [
        "Multi-step, sequence generation."
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "A4",
      "C4"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_002",
    "table_id": "arxiv_63416afda1",
    "question_type": "open_ended_reasoning",
    "question": "Tng-ji̍t ū chi̍t ê kè-uē su-iàu thong-iông hū-siong thàu-kòe bōe-iáⁿ, ūi-chiáⁿ-ê bô͘-hêng te̍k-teng, tû-liáu i ê èng-iōng jīm-bū gōa, ūi-chiáⁿ ê tiâu-kiāⁿ koh ūi-chiáⁿ koh tòe chòe kiâⁿ chòe hó khut-tih ke-tāi than kó͘-lē ê koan-liám?",
    "answer": [
      [
        "MarS/LMM sī chi̍t ê 'tuā-hêng ki-chhú bô͘-híng' (Large-scale foundation model), ē-tàng 'chē-po̍ah-tâⁿ, liân-sòa sán-seng' (Multi-step, sequence generation), hō͘ i tū-tâⁿ khah ióng-chū jīm-bū kap khah ióng-lêng chiap-siap thong-iông bōe-iáⁿ jīm-bū, pí khì DeepLOB lâi kóng, i ê bô͘-hêng sī 'sió, siú-kong chè-chok, kap bōe-tàng thiam-tiâu' (Small, handcrafted, and not scalable), chhiâng-chhiâng sī 'chi̍t-poâⁿ-châⁿ tō chhiâng-chhiâng' (Single-step or fixed-length) ê chhiâng-chhiâng."
      ]
    ],
    "evidence_cells": [
      "A1",
      "C1",
      "A3",
      "B3",
      "C3",
      "A4",
      "B4",
      "C4"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_003",
    "table_id": "arxiv_63416afda1",
    "question_type": "open_ended_reasoning",
    "question": "Kāu chit-ê piáu, hō͘ lâng kān-chhiú kap model ê tōa-sè hām i ê prediktsin tōa-hūn bô kâng ê la̍k-hē thê-chhut siáⁿ-chóng koan-hē?",
    "answer": [
      [
        "Chit-ê chu-liāu jīn-ûi ū chi̍t ê ti̍t-chiap ê koan-liân: \"Sió, khò chhiú-kū, hām bô hō͘ lâng kiâⁿ\" (DeepLOB) ê model thê-chhut ê prediktsin sī khan-chū \"Chi̍t-ê pō͘-chām hō͘-sī kò͘-tēng-tn̂g-tō͘\" ê hān-chè, tān-sī \"Tōa-hūi ki-châi model\" (MarS/LMM) chò-ûi khah lêng-hó, ē-tàng chò \"Chē pō͘-chām, sòaⁿ-tiâu chè-chok.\" Chit-ê jīn-ûi, koh khah tōa, koh khah ē-tàng hō͘ lâng kiâⁿ ê model, sī ū koh khah hō͘-chìn chham koh khah lêng-hó ê prediktsin lêng-le̍k."
      ]
    ],
    "evidence_cells": [
      "A3",
      "B3",
      "C3",
      "A4",
      "B4",
      "C4"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_63416afda1_004",
    "table_id": "arxiv_63416afda1",
    "question_type": "value",
    "question": "Tī chit ê dataset lāi-bīn, ū kúi-á bô-kāng ê hong-bīn lâi khu-pia̍t DeepLOB hām MarS/LMM?",
    "answer": [
      [
        "4"
      ]
    ],
    "evidence_cells": [
      "A1",
      "A2",
      "A3",
      "A4"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_005",
    "table_id": "arxiv_63416afda1",
    "question_type": "value",
    "question": "Chiu-jit ê m? (Which model is NOT described as 'Large-scale foundation model'?) Tui in ê chè-pia̍h chu-liāu (input features) siá chhut-lâi.",
    "answer": [
      [
        "DeepLOB",
        "Limit order book (LOB) data."
      ]
    ],
    "evidence_cells": [
      "A3",
      "C3",
      "B3",
      "A2",
      "B2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_006",
    "table_id": "arxiv_63416afda1",
    "question_type": "value",
    "question": "Koh-laitê model ê 'Model' hāng-bo̍k ê biâu-su̍t, ū saⁿ ê to̍k-li̍p ê hān-tiāⁿ-sèng, éng-hiat ki-tāi?",
    "answer": [
      [
        "DeepLOB"
      ]
    ],
    "evidence_cells": [
      "A3",
      "B3"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_63416afda1_007",
    "table_id": "arxiv_63416afda1",
    "question_type": "open_ended_reasoning",
    "question": "Tng-nn̄ DeepLOB ē-sái kái-piàn tòe 'Multi-step, sequence generation', koh ū nn̄g-ê kî-tha hāng-ba̍k tùi pió tēⁿ ū ē-sái tio̍h teh chiàⁿ-tòe piàn-tòe oân-á-á hāng-ba̍k ê tē-lí tòe chiàⁿ-tòe tē-lí ê ki-tîuⁿ?",
    "answer": [
      [
        "Tòe-tio̍h ē-sái tòe Multi-step generation chin tūi MarS/LMM, DeepLOB ê 'Model' ū ē-sái tòe 'Small, handcrafted, and not scalable' tòe chiàⁿ-tòe 'Large-scale foundation model', koh i ê 'Input Features' ū ē-sái tòe chiàⁿ-tòe LOB data tòe chiàⁿ-tòe chiàⁿ-tòe chiàⁿ-tòe chiàⁿ-tòe chiàⁿ-tòe chiàⁿ-tòe chiàⁿ-tòe 'High-frequency order-level data'."
      ]
    ],
    "evidence_cells": [
      "A4",
      "B4",
      "C4",
      "A3",
      "B3",
      "C3",
      "A2",
      "B2",
      "C2"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_008",
    "table_id": "arxiv_63416afda1",
    "question_type": "open_ended_reasoning",
    "question": "Koh-tùi nn̄g ê model ê su-iàu chhap-ji̍p chu-liāu ê bô-kāng, ū sím-me bô-kāng?",
    "answer": [
      [
        "DeepLOB su-iàu 'Limit order book (LOB) data,' chiah-sī chi̍t chióng te̍k-sû ê kim-chûng chu-liāu kiat-kò͘. Tùi-chāi MarS/LMM sī sú-iōng 'High-frequency order-level data,' chiah-sī koh-khah phó͘-thong, i chhoan-bûn tōa liōng kap sok-tō͘ ê chu-liāu."
      ]
    ],
    "evidence_cells": [
      "A2",
      "B2",
      "C2"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_009",
    "table_id": "arxiv_63416afda1",
    "question_type": "value",
    "question": "Oa-tiāⁿ chòe-tiāⁿ-kong-lêng chòe-chiàⁿ-kong-lêng ê hē-thóng, hiah-ê chòe-tiāⁿ-kong-lêng sī sím-mih lūi-hêng ê？",
    "answer": [
      [
        "Small, handcrafted, and not scalable"
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "A3",
      "B3"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_010",
    "table_id": "arxiv_63416afda1",
    "question_type": "open_ended_reasoning",
    "question": "Juah, ēnn-sû ū chi̍t ê lâng kan-na ū 'Limit order book (LOB) data' ē-tàng sú-iōng, iā beh chò 'General forecasting through simulation', tī chit ê su-kiû hā, nǎ chi̍t ê model ē chò-chha̍h (conflict), iân-hôaⁿ (and why)?",
    "answer": [
      [
        "Chit nn̄g ê model lóng ū chha̍h. DeepLOB ē-tàng sú-iōng LOB data, tān-sī i ê bô͘-hêng sī ūi-tio̍h 'Task specific forecasting,' m̄-sī general simulation. MarS/LMM ê bô͘-hêng sī ūi-tio̍h 'General forecasting,' tān-sī i su-iàu 'High-frequency order-level data,' m̄-sī LOB data. Chòe-āu, nn̄g ê model lóng bōe-tàng oân-choân hō͘-ha̍h bô͘-chha̍t (perfect fit) ài kiám-chiáⁿ (modification) he̍k-chiá kiám-hō͘ (compromise)."
      ]
    ],
    "evidence_cells": [
      "A1",
      "B1",
      "C1",
      "A2",
      "B2",
      "C2"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_63416afda1_011",
    "table_id": "arxiv_63416afda1",
    "question_type": "value",
    "question": "DeepLOB ê siunn-ìng jîn-bū sī sím-mih?",
    "answer": [
      [
        "Task specific forecasting."
      ]
    ],
    "evidence_cells": [
      "B1",
      "A2",
      "B2"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  }
]