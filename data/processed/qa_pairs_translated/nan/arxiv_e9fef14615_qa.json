[
  {
    "question_id": "arxiv_e9fef14615_001",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Koh model tit-tio̍h siōng koân ê F1 score tī 'ccfraud' dataset?",
    "answer": [
      [
        "Gemini"
      ]
    ],
    "evidence_cells": [
      "A4",
      "E4",
      "C4",
      "D4",
      "F4",
      "G4",
      "H4",
      "I4",
      "J4",
      "K4",
      "L4",
      "M4",
      "N4",
      "O4",
      "E10"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_002",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Tui 'GPT 4' model tī só͘-iáⁿ chè-tō͘ chòe chēⁿ-chèⁿ ê 'Acc' phiah-sò͘ sī táⁿ-koan?",
    "answer": [
      [
        "0.543"
      ]
    ],
    "evidence_cells": [
      "B1",
      "D1",
      "B5",
      "D5",
      "B9",
      "D9",
      "D10"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_e9fef14615_003",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Chiam-chit hō-chí ê dataset, tī-tú 'FinMA 7B' tit-tio̍h siōng-koân ê sîng-chi̍t, chiū-kúi liat-chhut tī hit ê jīm-hô sî-á tit-tio̍h 0 ê sîng-chi̍t ê model(s)?",
    "answer": [
      [
        "taiwan",
        "Falcon 7B"
      ]
    ],
    "evidence_cells": [
      "A11",
      "I11",
      "L11",
      "I1",
      "I2",
      "I3",
      "I4",
      "I5",
      "I6",
      "I7",
      "I8",
      "I9",
      "I12",
      "I10",
      "L10"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_004",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Tī 'TSA' ê dataset lāi-bīn, ūi-tiâu ki-lâi hō͘ i chòe-pêng ê model khah-chē ê performance kiảm-chē ê model sī tah-mih ê, koh chiâⁿ-chē ê decrease sī tah-mih ê sò͘-ba̍t?",
    "answer": [
      [
        "FinGPT 7B-lora",
        "0.80"
      ]
    ],
    "evidence_cells": [
      "A3",
      "I3",
      "J3",
      "I10",
      "J10"
    ],
    "reasoning_category": "Temporal Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_005",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "O·kài chiah-ê chu-liāu-chè siâⁿ-chòe 'Gemini' bô͘-hêng tit-tio̍h 0.90 í-siōng ê sêng-chek, chiâⁿ-chòe 'Chat GPT' bô͘-hêng tit-tio̍h 0.20 í-hā ê sêng-chek?",
    "answer": [
      [
        "ccfraud"
      ],
      [
        "taiwan"
      ]
    ],
    "evidence_cells": [
      "A4",
      "C4",
      "E4",
      "A11",
      "C11",
      "E11",
      "C10",
      "E10"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_006",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Tùi 'LendingClub' chū-liāu-chāi, siáⁿ chi̍t-ê luē-iòng ê chóng-sò͘-ba̍k ē-sái hō͘ saⁿ ê tē-it-miāⁿ hō͘-chòe ê bô-chāi ê siáⁿ chi̍t-ê phò-chè? Sio̍k chi̍t ê sió-siòng ê kòe-tō͘.",
    "answer": [
      [
        "41.3%"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C6",
      "D6",
      "E6",
      "F6",
      "G6",
      "H6",
      "I6",
      "J6",
      "K6",
      "L6",
      "M6",
      "N6",
      "O6"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_e9fef14615_007",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Rau `LLaMA2 70B` model ê kám-chhiáⁿ ê siau-tū nā sêng-tiāⁿ 10%, in-ê boé-chi̍p kám-chhiáⁿ tī só͘-ū chhà-giām ê jīm-bū tiong ē-sī siáⁿ-chōe? Chheh-kàu saⁿ-ê sió-sò͘ tiám.",
    "answer": [
      [
        "0.354"
      ]
    ],
    "evidence_cells": [
      "G1",
      "G2",
      "G3",
      "G4",
      "G5",
      "G6",
      "G7",
      "G8",
      "G9",
      "G11",
      "G12",
      "G10"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_008",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Khuàn-tzò 'F1' hō-sò-sò 'MicroF1' ê metric sóan ê sū-bū. 'GPT 4' kap 'Gemini' nn̂g ê model ūi-tio̍h sì-siông ê hêng-uī koan-hē bô? Kái-soeh lí ê lí-iû.",
    "answer": [
      [
        "Bô chin kiông ê chèng-siông koan-lian-hē, tān-sī ū chi̍t ê bîng-chhián ê hêng-uī kai-chân. Tī F1 ki-chū ê sū-bū téng-bīn, Gemini it-tîng chhiau-kòe tōa-sò͘ chhāi GPT 4. Tùi 'ccfraud' kap 'taiwan' ê su-liōng, Gemini ê score (0.90 kap 0.95) khah koân khah chē chhāi GPT 4 ê score (0.55 nn̄g ê). Tùi 'LendingClub', Gemini (0.65) iáu sī tōa-to̍k koân khah chē chhāi GPT 4 (0.55). Kan-na tī 'MLESG' su-liōng, in ê score chin chha-put-to̍k à (0.35 vs 0.34). Chit-ê sī chioh-sī, chiàⁿ-chóng in ê hêng-uī bô chin chò-hóe, Gemini it-tîng sī khah hó ê model tùi chit-ê te̍k-tēng ê F1-chè-liông ê sū-bū."
      ]
    ],
    "evidence_cells": [
      "B4",
      "D4",
      "E4",
      "B6",
      "D6",
      "E6",
      "B11",
      "D11",
      "E11",
      "B12",
      "D12",
      "E12",
      "D10",
      "E10"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_e9fef14615_009",
    "table_id": "arxiv_e9fef14615",
    "question_type": "value",
    "question": "Tùi pi-kó-sò͘ lâi kóng, ū nn̄g-ê dataset hō͘-lâng khòaⁿ-kîⁿ to̍h-ài iân-chúi, che sī lí-kái ū khó-lêng sī chòe-koâⁿ siâⁿ-phòe hō͘ sió-sài ia̍h-sī ū chi̍t hāng jīm-bū bô tiâu-lō͘ sió-sài siâⁿ-phòe ê chha-ì?",
    "answer": [
      [
        "FNXL"
      ],
      [
        "ECTSUM"
      ]
    ],
    "evidence_cells": [
      "A7",
      "C7",
      "D7",
      "E7",
      "F7",
      "G7",
      "H7",
      "I7",
      "J7",
      "K7",
      "L7",
      "M7",
      "N7",
      "O7",
      "A8",
      "C8",
      "D8",
      "E8",
      "F8",
      "G8",
      "H8",
      "I8",
      "J8",
      "K8",
      "L8",
      "M8",
      "N8",
      "O8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_e9fef14615_010",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Chit ê 'Gemini' phín-lūi ê su-iàu, hō͘ 'taiwan' chhit-siâⁿ sī siáⁿ-mih kiâⁿ-chè lâi chòe chē chhut-lâi ê sîng-chiàu, kap in-ūi siáⁿ-mih?",
    "answer": [
      [
        "Tùi Gemini phín-lūi lâi kóng, 'taiwan' chhit-siâⁿ ê su-iàu (0.95) sī siōng chē ê sîng-chiàu. Kî-tiong chin-chiok bē-su-chē ê Gemini ê bô-lêng su-iàu ê sîng-chiàu, phêng-kūn tāi-khài sī 0.615. 0.95 ê su-iàu sī siōng koân ê sî-iáⁿ, kap pí khah chē ê su-iàu khah hn̄g pí lí-sûn. Chit ê bē-sio̍k-chāi ê koân sîng-chiàu, jīn-ûi Gemini phín-lūi chin chiap-ha̍p 'taiwan' chhit-siâⁿ kap 'F1' êMetrics，Ū hō͘-chòe chit ê Metrics chin chiap-ha̍p Gemini phín-lūi ê sîng-chiàu."
      ]
    ],
    "evidence_cells": [
      "A11",
      "B11",
      "E11",
      "E1",
      "E2",
      "E3",
      "E4",
      "E5",
      "E6",
      "E7",
      "E8",
      "E9",
      "E12",
      "E10"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_e9fef14615_011",
    "table_id": "arxiv_e9fef14615",
    "question_type": "open_ended_reasoning",
    "question": "Koh kho-lait thong-kòe entity hù-kè (NER, FINER-ORD) kap tsìng-tshùn hun-lâi (FPB, SC) ngiam-tsuánn, lóng tsán-sī tshut hó-sîng-tōo ê ki-khì-jîn (model)?",
    "answer": [
      [
        "GPT-4 thong-kòe entity hù-kè kap tsìng-tshùn hun-lâi ê su-kì-pâi (dataset), lóng tit-tioh hó-ê EntityF1 kap F1 tiāu-sòo, pí kî-thann ki-khì-jîn (model) koh hó."
      ]
    ],
    "evidence_cells": [
      "A2",
      "C2",
      "D2",
      "A3",
      "C3",
      "D3",
      "A5",
      "J5",
      "A9",
      "J9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]