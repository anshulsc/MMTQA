[
  {
    "question_id": "arxiv_82ccef75df_001",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Ūi-hônn--ê hong-huat sī ūi-hônn ê Llama hē-lia̍t ê LLM (chhiūⁿ Llama2, LLaMA-2, FinLlama téng-téng) iah?",
    "answer": [
      [
        "7"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B2",
      "B3",
      "B5",
      "B7",
      "B8",
      "B9"
    ],
    "reasoning_category": "Numerical Aggregation"
  },
  {
    "question_id": "arxiv_82ccef75df_002",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Guáⁿ chi̍t chióng èng-iōng chiap-chhiam liáu siōng chē khoán bô-kâng ê chhoan-chāi chu-liāu lâi chi-oân?",
    "answer": [
      [
        "Financial sentiment analysis and return prediction"
      ]
    ],
    "evidence_cells": [
      "C1",
      "C2",
      "C3",
      "C4",
      "C5",
      "C6",
      "C7",
      "C8",
      "C9",
      "D3"
    ],
    "reasoning_category": "Comparative Reasoning"
  },
  {
    "question_id": "arxiv_82ccef75df_003",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Tī iōng 'StockGPT' lūi-hêng ê hong-hoat, chu-liāu ê goân-tē sī siáⁿ-mih?",
    "answer": [
      [
        "AlphaFin"
      ]
    ],
    "evidence_cells": [
      "B6",
      "C6"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_82ccef75df_004",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Liet chē 'Method/Paper' bu̍t chiūⁿ ū chi̍t ê model hō chò 'GPT' tī i ê miâ, koh hō͘ iōng tī kám-chè kó͘-chiáⁿ ūn-tāng ê kiat-lāi?",
    "answer": [
      [
        "[25]"
      ]
    ],
    "evidence_cells": [
      "A5",
      "B5",
      "D5",
      "B1",
      "D1"
    ],
    "reasoning_category": "Conditional Reasoning"
  },
  {
    "question_id": "arxiv_82ccef75df_005",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Tī lia̍t-chhut ê hong-sek tang-tiong, ū kúi-ê chha-put-to̍h ê chok-iōng sī ū kóng-kàu 'chè-tōan', 'chè-tōan-tiâu', he̍k-chiá 'chhut-sû'?",
    "answer": [
      [
        "55.56%"
      ]
    ],
    "evidence_cells": [
      "D1",
      "D2",
      "D3",
      "D4",
      "D5",
      "D6",
      "D7",
      "D8",
      "D9"
    ],
    "reasoning_category": "Proportional/Ratio Analysis"
  },
  {
    "question_id": "arxiv_82ccef75df_006",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Hia-ê hong-huat sú-iōng ê su-liāu lâi-goân sī chi̍t-ê to̍k-it ê miâ-chheng (AlphaFin), bô sī pâi-lia̍t su-liāu lūi-hêng ê lí-lūn?",
    "answer": [
      [
        "Stock-Chain framework [27]"
      ]
    ],
    "evidence_cells": [
      "A6",
      "C1",
      "C2",
      "C3",
      "C4",
      "C5",
      "C6",
      "C7",
      "C8",
      "C9"
    ],
    "reasoning_category": "Outlier Detection"
  },
  {
    "question_id": "arxiv_82ccef75df_007",
    "table_id": "arxiv_82ccef75df",
    "question_type": "open_ended_reasoning",
    "question": "Nāi-ia̍h 'FinLlama [35]' ê chè-chok-chiá kā 'S&P 500' kap 'market indices' kā su-kì, in ê kè-e̍k ē-tàng chòe-chòe tò-tī phóe-chòe ê kiàⁿ-tiâu ê ēng-túi, chin chhau-iúⁿ, chin chhau-iúⁿ?",
    "answer": [
      [
        "In ê kè-e̍k ē-tàng chòe-chòe tò-tī 'Predicting stock movements'. Che sī in-ūi phóe-chòe '[25]' iōng chin siâng-siâng ê su-kì ha̍p-chòe ('S&P 500', 'financial reports', 'market indices') chòe chi̍t-ê te̍k-tēng ê ēng-túi, chiá FinLlama í-keng iōng 'Earnings reports'."
      ]
    ],
    "evidence_cells": [
      "C5",
      "D5",
      "C7",
      "D7"
    ],
    "reasoning_category": "Hypothetical Reasoning"
  },
  {
    "question_id": "arxiv_82ccef75df_008",
    "table_id": "arxiv_82ccef75df",
    "question_type": "open_ended_reasoning",
    "question": "Tùi chit ê phiau, ū bat teh lia̍h ê Lûi-chū-lú bô͘-hêng ê sò͘-liōng kah tùi kó͘-sū ê tē-tiám ê sò͘-liōng ū koan-hē bē?\n",
    "answer": [
      [
        "Ū, chin ch Bat teh lia̍h ê koan-hē. Chit-ê hong-hoat, i bat lia̍h chin Lûi-chū-lú bô͘-hêng (Multimodal Gen-AI [9], Fine-tuning LLMs [8], [25]), mā ū chin, chin ch Bat teh lia̍h ê kó͘-sū tē-tiám (sio-sú-sī 4, 1 kah 4). Tò-hoat, bat lia̍h chi̍t ê Lûi-chū-lú bô͘-hêng ê hong-hoat, chin ch Bat teh lia̍h khah sió-sió tē-tiám (chhin-chhiūⁿ Stock-Chain framework [27] í-ki̍p SAPPO [37]). Che sī hoat-koaⁿnn, khah chē Lûi-chū-lú bô͘-hêng ê hong-hoat ū kiàn-siat lâi hō͘-chú tùi chin ch Bat teh lia̍h ê chu-liāu lâi hō͘-chú."
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "B2",
      "C2",
      "B3",
      "C3",
      "B4",
      "C4",
      "B5",
      "C5",
      "B6",
      "C6",
      "B7",
      "C7",
      "B8",
      "C8",
      "B9",
      "C9"
    ],
    "reasoning_category": "Correlation Inference"
  },
  {
    "question_id": "arxiv_82ccef75df_009",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "Lai 'LLM Model' ath-chá 'Data' chit-ê phiah ū koh-khah chē ê bu̍t-ê lia̍t-chhut (iōng kò-hō ia̍h-sī 'and' hun-khui)?",
    "answer": [
      [
        "Data"
      ]
    ],
    "evidence_cells": [
      "B1",
      "B2",
      "B5",
      "C1",
      "C3",
      "C5",
      "C7",
      "C8"
    ],
    "reasoning_category": "Structural/Metadata Reasoning"
  },
  {
    "question_id": "arxiv_82ccef75df_010",
    "table_id": "arxiv_82ccef75df",
    "question_type": "value",
    "question": "La̍k-cho̍k sū-líng Llama hē-li̍p ê koat-tó͘, kap ē-tàng iōng `news` ê chu-liāu lâi tùi-chè ê lōe-iông ūi-chí ū sím-mi̍h?",
    "answer": [
      [
        "AI-assisted investment analysis"
      ],
      [
        "Stock return prediction"
      ],
      [
        "Financial sentiment analysis and return prediction"
      ],
      [
        "Trading strategies"
      ],
      [
        "Portfolio optimization"
      ]
    ],
    "evidence_cells": [
      "B1",
      "C1",
      "D1",
      "B2",
      "C2",
      "D2",
      "B3",
      "C3",
      "D3",
      "B7",
      "C7",
      "D7",
      "B9",
      "C9",
      "D9"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  },
  {
    "question_id": "arxiv_82ccef75df_011",
    "table_id": "arxiv_82ccef75df",
    "question_type": "open_ended_reasoning",
    "question": "Sitiāⁿ-chiáⁿ LLM model ū teh iōng-chò chò thioh-liâu kè-kà ī-chhek, chiūⁿ-sī ūi-tio̍h tio̍h-liâu ê kè-kà i-chhek, i koh teh iōng siáⁿ-mi̍h chhit-á ūi-tio̍h?",
    "answer": [
      [
        "Ūi-tio̍h thio̍h-liâu ê kè-kà ī-chhek, teh iōng Distilled RoBERT kap LLaMA3-8B model. Teh iōng ê chhit-á ū Financial news data, S&P- Bigdata23, Bigdata22, ACL18, kap CIKM1."
      ]
    ],
    "evidence_cells": [
      "B4",
      "B8",
      "D4",
      "D8"
    ],
    "reasoning_category": "Multi-Hop Reasoning"
  }
]