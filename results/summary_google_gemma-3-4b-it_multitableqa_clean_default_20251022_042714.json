{
  "metadata": {
    "model_name": "google/gemma-3-4b-it",
    "dataset_file": "dataset_combined_final.jsonl",
    "response_file": "google_gemma-3-4b-it_multitableqa_clean_default_20251022_042714.jsonl",
    "total_samples": 58480
  },
  "overall_metrics": {
    "exact_match": 0.01783515731874145,
    "f1_score": 0.05425599853625243,
    "bleu_score": 0.03685664689431389,
    "processed_samples": 58480,
    "skipped_samples": 0,
    "no_match_samples": 0,
    "parse_errors": 0,
    "cuda_errors": 0,
    "table_errors": 0,
    "total_responses": 58480
  },
  "per_language_metrics": {
    "ar": {
      "exact_match": 0.014504431909750202,
      "f1_score": 0.039068406982986144,
      "bleu_score": 0.025741100214717757,
      "samples": 2482
    },
    "az": {
      "exact_match": 0.014632107023411372,
      "f1_score": 0.0448395217284821,
      "bleu_score": 0.03073389758374764,
      "samples": 2392
    },
    "bn": {
      "exact_match": 0.015983606557377048,
      "f1_score": 0.033165446817054973,
      "bleu_score": 0.024473948156380387,
      "samples": 2440
    },
    "cs": {
      "exact_match": 0.01771004942339374,
      "f1_score": 0.06378900714469543,
      "bleu_score": 0.042837093703678594,
      "samples": 2428
    },
    "en": {
      "exact_match": 0.03666921313980138,
      "f1_score": 0.11221423110985206,
      "bleu_score": 0.07993079964198659,
      "samples": 2618
    },
    "es": {
      "exact_match": 0.02337228714524207,
      "f1_score": 0.06993763462160932,
      "bleu_score": 0.047644542797476486,
      "samples": 2396
    },
    "fr": {
      "exact_match": 0.024471173786810452,
      "f1_score": 0.0780714975450629,
      "bleu_score": 0.05352606411220426,
      "samples": 2411
    },
    "hi": {
      "exact_match": 0.014669926650366748,
      "f1_score": 0.035396675008456564,
      "bleu_score": 0.02477842634247813,
      "samples": 2454
    },
    "id_casual": {
      "exact_match": 0.02135523613963039,
      "f1_score": 0.07073052137408493,
      "bleu_score": 0.047343066876862704,
      "samples": 2435
    },
    "id_formal": {
      "exact_match": 0.02506162695152013,
      "f1_score": 0.07426083805059223,
      "bleu_score": 0.051762190426803155,
      "samples": 2434
    },
    "it": {
      "exact_match": 0.02341824157764996,
      "f1_score": 0.07062282390500639,
      "bleu_score": 0.04772088317254629,
      "samples": 2434
    },
    "ja_formal": {
      "exact_match": 0.015238879736408566,
      "f1_score": 0.034534615418745446,
      "bleu_score": 0.02617867792396487,
      "samples": 2428
    },
    "jv_krama": {
      "exact_match": 0.015220074043603456,
      "f1_score": 0.0540655943755316,
      "bleu_score": 0.03405312301718436,
      "samples": 2431
    },
    "jv_ngoko": {
      "exact_match": 0.015295576684580404,
      "f1_score": 0.05500847540349167,
      "bleu_score": 0.03491808898859402,
      "samples": 2419
    },
    "ko_formal": {
      "exact_match": 0.013109381401065138,
      "f1_score": 0.03745503431862861,
      "bleu_score": 0.025690022009221467,
      "samples": 2441
    },
    "mr": {
      "exact_match": 0.01394585726004922,
      "f1_score": 0.03249463307073558,
      "bleu_score": 0.022817550464791756,
      "samples": 2438
    },
    "nan": {
      "exact_match": 0.008041817450743867,
      "f1_score": 0.031393694946087805,
      "bleu_score": 0.019058374523624976,
      "samples": 2487
    },
    "ru_formal": {
      "exact_match": 0.019087136929460582,
      "f1_score": 0.04762757824867631,
      "bleu_score": 0.033926561682122734,
      "samples": 2410
    },
    "sc": {
      "exact_match": 0.014320785597381341,
      "f1_score": 0.04928347757683985,
      "bleu_score": 0.03153677266028343,
      "samples": 2444
    },
    "si_formal_spoken": {
      "exact_match": 0.015207562679819153,
      "f1_score": 0.04089558136910141,
      "bleu_score": 0.028231893306213264,
      "samples": 2433
    },
    "su_loma": {
      "exact_match": 0.014749262536873156,
      "f1_score": 0.05450827262026554,
      "bleu_score": 0.034752493765323106,
      "samples": 2373
    },
    "th": {
      "exact_match": 0.016049382716049384,
      "f1_score": 0.05327638784976934,
      "bleu_score": 0.03528553975485068,
      "samples": 2430
    },
    "tl": {
      "exact_match": 0.02048494983277592,
      "f1_score": 0.07640367972390207,
      "bleu_score": 0.051181223345304595,
      "samples": 2392
    },
    "zh_cn": {
      "exact_match": 0.01440329218106996,
      "f1_score": 0.04040090537935436,
      "bleu_score": 0.028328953615310154,
      "samples": 2430
    }
  }
}